# -*- coding: utf-8 -*-
"""TP1_agustina_7_2022_06_29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12pLz0jL0gNwnLC4VjztkQ06t4KSRz2XP

<p align="center">
_____________________________________________________________________________________________________________________________

<br>
<br>
  <img src="https://www.estudiaradistancia.com.ar/logos/original/logo-universidad-de-buenos-aires.webp" height=180 />
  <img  src="https://confedi.org.ar/wp-content/uploads/2020/09/fiuba_logo.jpg" height="180">
<br>
_____________________________________________________________________________________________________________________________
<br>
<br>
<font size="+3">
[71.12] An√°lisis Num√©rico I
<br>
Trabajo Pr√°ctico I
<br>
Primer Cuatrimestre 2022
</font>
<br>
<br>
_____________________________________________________________________________________________________________________________
<br>
<br>
<font size="+2">
Desarrollo de m√©todos num√©ricos de busqueda de ra√≠ces e interpolacion
<br>
de Spline c√∫bica para su aplicaci√≥n en problemas de optimizaci√≥n industrial. 
</font>
<br>
<br>
_____________________________________________________________________________________________________________________________
<br>
<br>
<font size="+2">
AUTORES
</font>
<br>
<font size="+1">
Gamberale Luciano Martin,
<br>  
Veiga Angel Martin,
<br>
Godoy Dupont Mateo,
<br>
Vasquez Jimenez Miguel Angel,
</font>
<br>
<br>
<font size="+2">
DOCENTES
</font>
<br>
<font size="+1">
Sassano Myriam Patricia
<br>
Garcia Ezequiel
<br>
Husain Santiago
<br>
Payva Matias
<br>
Turano Maria Agustina
<br>
Vera Ramiro
</font>
<br>
<br>
<br>

_____________________________________________________________________________________________________________________________
</p>

___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# √çndice

0. Introducci√≥n
    - 0.1 Objetivos
    - 0.2 Introducci√≥n
1. Plan de producci√≥n:
    - 1.1 Implementacion de metodos de busqueda de Raices:  
        - 1.1.1 Definiciones, funciones e imports auxiliares:
            - 1.1.1.1 Imports
            - 1.1.1.2 Calculo de orden de convergencia (Œ±)
            - 1.1.1.3 Calculo de la constante asint√≥tica (Œª)
            - 1.1.1.4 Funciones de iteraciones funcionales
                - 1.1.1.4.1 Para m√©todos de semilla √∫nica
                - 1.1.1.4.2 Caso particular m√©todo Secante (semilla doble)
            - 1.1.1.5 Funciones para extraccion de datos una vez completada la aplicacion de los metodos para problemas especificos
                - 1.1.1.5.1 Extraccion de valores importantes tras biseccion
                - 1.1.1.5.2 Extraccion de valores importantes tras metodos de iteracion funcional
                - 1.1.1.5.3 Funci√≥n auxiliar para representar los valores en tablas
                - 1.1.1.5.4 Extracci√≥n de valor obtenido en ultima iteraci√≥n: pn
            - 1.1.1.6 Criterios de paro:
        - 1.1.2 Metodo de la biseccion
        - 1.1.3 Metodo Punto Fijo
        - 1.1.4 Metodo Newton-Raphson
        - 1.1.5 Metodo Newton-Raphson modificado para raices multiples
        - 1.1.6 Metodo Secante
    - 1.2 Planteo del problema
        - 1.2.1 (Pregunta a) Formule el problema y graf√≠quelo.
        - 1.2.2 (Pregunta b) Hallar las cantidades a fabricar del producto ‚ÄúE41‚Äù utilizando los m√©todos vistos en clase:
            - 1.2.2.1 Bisecci√≥n/ Busqueda Binaria / Metodo de Arranque:
            - 1.2.2.2 M√©todo del Punto Fijo:
            - 1.2.2.3 M√©todo de Newton-Raphson:
            - 1.2.2.4 M√©todo de Newton-Raphson modificado:
            - 1.2.2.5 M√©todo de la Secante:
        - 1.2.3 (Pregunta c) Realizar una tabla con los resultados de las iteraciones, convergencia P y la constante asint√≥tica Œª.
            - 1.2.3.1 M√©todo de Bisecci√≥n
            - 1.2.3.2 M√©todo de Punto Fijo
            - 1.2.3.3 M√©todo de Newton-Raphson
            - 1.2.3.4 M√©todo de Newton-Raphson Modificado
            - 1.2.3.5 M√©todo de la Secante
        - 1.2.4 (Pregunta d) Compare los resultados obtenidos para los distintos m√©todos y cotas, grafique el orden de convergencia P y la constante asint√≥tica Œª para todos los casos. Realice un gr√°fico log10(Œîx) vs iteraciones, para visualizar el comportamiento de la constante asint√≥tica y el orden de convergencia. Discuta ventajas y desventajas. ¬øSon las que esperaba en base a la teor√≠a?
            - 1.2.4.1 Funciones auxiliares para plots:
            - 1.2.4.2 Graficos orden de convergencia Œ± vs Iteraciones
            - 1.2.4.3 Graficos constante asint√≥tica Œª vs Iteraciones
            - 1.2.4.4 Graficos log10(Œîx) vs Iteraciones
2. Splines para aproximacion de curvas
    - 2.1 Implementaci√≥n del m√©todo de iterpolacion de Spline c√∫bica:
        - 2.1.1 Definiciones de funciones de c√°lculo de coeficientes:
        - 2.1.2 Definiciones de funciones auxiliares para ploteo:
        - 2.1.3 Metodo de interpolaci√≥n de Spline c√∫bica
    - 2.2 Planteo del problema
        - 2.2.1 Uso de datos, interpolaci√≥n y tabla de coeficientes resultantes:
        - 2.2.2 Gr√°fico
        - 2.2.3 Conclusiones

3. Conclusiones generales

4. Referencias

# ***0. Introducci√≥n***

### 0.1 Objetivos

El presente trabajo se divide en dos problemas a resolver:
- Plan de producci√≥n:
    - Se analiza la cantidad m√≠nima requerida de un producto industrial a partir de dos restricciones principales relacionadas con la rentabilidad y la producci√≥n.
    - Se desarrolla el an√°lisis por medio del uso de m√©todos num√©ricos para la obtenci√≥n de ra√≠ces de funciones, obteniendo as√≠ aproximaciones de la cantidad mencionada anteriormente.
    - Se implementaron los algoritmos correspondientes a los siguientes m√©todos num√©ricos:
        - Bisecci√≥n
        - Punto Fijo
        - Newton-Raphson
        - Newton-Raphson para ra√≠ces multiples
        - Secante
    - Se realizan an√°lisis previos con el fin de garantizar el cumplimiento de las condiciones necesarias para aplicar cada uno de los m√©todos.
    - Se realizan an√°lisis posteriores a la aplicaci√≥n de los m√©todos y la correspondiente comparativa entre lo obtenido y lo esperado seg√∫n las bases te√≥ricas. 
    - Se analizan gr√°ficamente los resultados los m√©todos, incluyendo propiedades de los mismos como son: constante asint√≥tica y orden de convergencia. 
- Spline para aproximaci√≥n de curvas:
    - Se busca realizar una aproximaci√≥n de una funci√≥n partida dado un conjunto de puntos de la misma y sus derivadas en los extremos. Para ello se utiliza la interpolaci√≥n de Spline c√∫bica ligada.
    - Se implementan las funciones necesarias para realizar el c√°lculo de coeficientes independientes, lineales, cuadr√°ticos y c√∫bicos mediante la forma matricial tridiagonal.
    - Se analizan gr√°ficamente los resultados de las interpolaciones y se comparan con los puntos originales de la tabla.

### 0.2 Introducci√≥n

Inicialmente se investiga el funcionamiento y el desempe√±o de los distintos m√©todos num√©ricos aplicados a un problema particular.

Dicho problema consiste en la busqueda de la cantidad m√≠nima requerida de producto dadas dos restricciones explicadas m√°s adelante.

En conjunto con el valor m√≠nimo esperado como respuesta al problema planteado, se espera corroborar que el desempe√±o de los m√©todos se corresponde a las propiedades mencionadas en el objetivo del trabajo para cada uno de ellos.

Posteriormente se investiga una aplicaci√≥n pr√°ctica del m√©todo para interpolaci√≥n de Spline c√∫bica ligada desarrollada por medio de su forma matricial cuya deducci√≥n se encuentra en su respectivo apartado en el cuerpo del trabajo.

Se espera que la aproximaci√≥n resultante cumpla con todas las condiciones planteadas en la secci√≥n respectiva del cuerpo del trabajo y que se reflejen gr√°ficamente.

# ***1. Plan de producci√≥n:***

Se le solicita el √°rea "Supply Chain" que indique qu√© mix de productos es m√°s conveniente
fabricar mensualmente dada una serie de restricciones que tiene la planta y la contribuci√≥n
marginal que ofrece cada producto.

 Como nuevo pasante del √°rea le asignan el c√°lculo para
el producto estrella de la empresa, acero de calidad ‚ÄúE41‚Äù utilizado para fabricar perfiles de
"Steel Frame".

Consulta con el √°rea de Rentabilidad la utilidad unitaria del producto, y le informan que la
misma responde a la siguiente funci√≥n: $$0,001¬∑x¬∑(x‚àí1000kg
)^2$$, donde x es la cantidad de producto
a producir (medida en kilogramos), y que para producirse debe alcanzarse los $25000
de contribuci√≥n mensual.

Luego, llama al √°rea de Producci√≥n y le consulta por las restricciones que tiene la l√≠nea donde
se fabrica este producto.

Le informan que para que se justifique hacer el set up para prender
la m√°quina correspondiente, se deber√°n fabricar al menos $827 kg$ del mismo.

## ***1.1  Implementacion de metodos de busqueda de Raices:***

### **1.1.1 Definiciones, funciones e imports auxiliares:**

#### *1.1.1.1  Imports*
"""

import matplotlib.pyplot as plt
from matplotlib.ticker import (AutoMinorLocator, MultipleLocator) 
import numpy as np
from math import isclose
import pandas as pd

MAX_ITERACIONES = 30
MAX_VALOR_DE_ERROR = 1e+20
MIN_VALOR_DE_ERROR = 1e-12

ERROR_FUERA_DE_RANGO = "La cota del error es un valor muy cercano a cero no representable."
ERROR_MAX_ITERACIONES = "Ra√≠z no encontrada: Se lleg√≥ al maximo de iteraciones sin encontrar la raiz."
ERROR_EJECUCION = "Error en los parametros al ejecutar el m√©todo."
ERROR_TAMA√ëO_LISTA = "La listas recibidas deben poseer el mismo tama√±o."
ERROR_DIVERGENCIA = "El m√©todo diverge para estos par√°metros"

COTA_DE_ERROR_1 = 1e-05
COTA_DE_ERROR_2 = 1e-13

"""Tener en cuenta que para los calculos de orden de convergencia y constante asint√≥tica se hace una aproximaci√≥n en base a los l√≠mites que los definen. Entre mayor sea el n√∫mero de iteraciones m√°s precisa ser√° esa aproximaci√≥n.
Por definici√≥n se ten√≠a:

$\displaystyle{\lim_{n \to \infty}}$ $ \frac{|p_{n+1}-p|}{|p_n-p|^{Œ±}} = \lambda$

#### *1.1.1.2 Calculo de orden de convergencia ($\alpha$)*

$\alpha_n \cong \frac{log|({x_n-x_{n-1})/(x_{n-1} - x_{n-2})|}}{log|(x_{n-1}-x_{n-2})/(x_{n-2}-x_{n-3})|}$
"""

def calcular_orden_de_convergencia_alfa(lista_pn):
    lista_orden_de_convergencia = []

    for i in range(len(lista_pn)):
        alpha_i = None
        if ( (i > 2) and not(isclose((lista_pn[i]-lista_pn[i-1]) ,0, rel_tol = MIN_VALOR_DE_ERROR))):
            alpha_i = ((np.log(abs((lista_pn[i]-lista_pn[i-1])/(lista_pn[i-1]-lista_pn[i-2])))) / (np.log(abs((lista_pn[i-1]-lista_pn[i-2])/(lista_pn[i-2]-lista_pn[i-3])))))
        
        lista_orden_de_convergencia.append(alpha_i)
    return lista_orden_de_convergencia

"""#### *1.1.1.3 Calculo de la constante asint√≥tica ($\lambda$)*

$\lambda_{n} \cong  \frac{\Delta x_n}{\Delta x_{n-1}^{\alpha_{n}}}$
"""

def calcular_cte_asintotica_lambda(lista_errores, lista_alfas):
    if(len(lista_errores) <= len(lista_alfas)-1):
        print(ERROR_TAMA√ëO_LISTA)
        return None

    lista_cte_asintotica = []

    for i in range(len(lista_alfas)):
        lambda_i = None
        if(i > 2):
            if ((lista_errores[i-1] != None) and (lista_alfas[i] != None)) : # Condicion necesaria por metodo Secante
                lambda_i = lista_errores[i] / (lista_errores[i-1] ** lista_alfas[i])
            lista_cte_asintotica.append(lambda_i)
        else:
            lista_cte_asintotica.append(None)

    return lista_cte_asintotica

"""#### *1.1.1.4 Funciones de iteraciones funcionales*

###### 1.1.1.4.1 Para m√©todos de semilla √∫nica
$g(x) = x - ùùã(x)f(x) $ ;

con $ùùã(x)$ definida dependiedo del m√©todo (Punto fijo, NR, NR modificado)
"""

def iteracion_funcional_recursiva(g, numero_iteracion, tolerancia, lista_resultados):
    if(numero_iteracion == MAX_ITERACIONES):  
        print(ERROR_MAX_ITERACIONES)
        return lista_resultados, False

    pn_1 = lista_resultados[numero_iteracion-1][0]
    pn = g(pn_1)

    error_actual = np.abs(pn_1 - pn)
    if(error_actual > MAX_VALOR_DE_ERROR):
        print(ERROR_DIVERGENCIA)
        return lista_resultados, False
    if (isclose(error_actual,0, rel_tol = MIN_VALOR_DE_ERROR) or error_actual == 0):             #Caso de que el error sea menor que la capacidad de la computadora
        print(ERROR_FUERA_DE_RANGO)
        error_actual =  MIN_VALOR_DE_ERROR
        lista_resultados_n = [pn, error_actual]  #[pn, error]  
        lista_resultados.append(lista_resultados_n)
        return lista_resultados, True

    lista_resultados_n = [pn, error_actual]  #[pn, error]  
    lista_resultados.append(lista_resultados_n)
                            
    if(error_actual < tolerancia):
        return lista_resultados, True

    return iteracion_funcional_recursiva(g, numero_iteracion+1, tolerancia, lista_resultados)

"""###### 1.1.1.4.2 Caso particular m√©todo Secante (semilla doble)
$g(x,y) = x - ùùã(x,y)f(x)$ 
"""

def iteracion_funcional_recursiva_de_dos_semillas(g, numero_iteracion, tolerancia, lista_resultados):
    if(numero_iteracion == MAX_ITERACIONES): 
        return lista_resultados, False

    pn_1 = lista_resultados[numero_iteracion-1][0]
    pn_2 = lista_resultados[numero_iteracion-2][0]
    pn = g(pn_1,pn_2)
    

    error_actual = np.abs(pn - pn_1)
    if(error_actual > MAX_VALOR_DE_ERROR):
        print(ERROR_DIVERGENCIA)
        return lista_resultados, False
    if (isclose(error_actual,0, rel_tol = MIN_VALOR_DE_ERROR) or error_actual == 0):             #Caso de que el error sea menor que la capacidad de la computadora
        print(ERROR_FUERA_DE_RANGO)
        error_actual =  MIN_VALOR_DE_ERROR
        lista_resultados_n = [pn, error_actual]  #[pn, error]  
        lista_resultados.append(lista_resultados_n)
        return lista_resultados, True

    lista_resultados_n = [pn, error_actual]  # [pn, error]  
    lista_resultados.append(lista_resultados_n)
        
    if(error_actual < tolerancia):
        return lista_resultados, True

    return iteracion_funcional_recursiva_de_dos_semillas(g, numero_iteracion+1, tolerancia, lista_resultados)

"""#### *1.1.1.5 Funciones para extraccion de datos una vez completada la aplicacion de los metodos para problemas especificos*

###### 1.1.1.5.1 Extraccion de valores importantes tras biseccion 
Dichos valores son:

$p_n$ o de errores: $|p_n-p_{n-1}|$  de cada iteraci√≥n a partir de la
lista con resultados totales del m√©todo de biseccion (exclusivamente)
"""

def extraer_pn_biseccion(lista_resultados):
    lista_xi = []

    for i in range(len(lista_resultados)):
        lista_xi.append(lista_resultados[i][2])

    return lista_xi



def extraer_errores_biseccion(lista_resultados):
    lista_xi = []

    for i in range(len(lista_resultados)):
        lista_xi.append(lista_resultados[i][3])

    return lista_xi

"""###### 1.1.1.5.2 Extraccion de valores importantes tras metodos de iteracion funcional
Dichos valores son:

$p_n$ o de errores: $|p_n-p_{n-1}|$  de cada iteraci√≥n a partir de la
lista con resultados totales de cualquiera de los metodos con iteracion funcional
"""

def extraer_pn(lista_resultados):
    lista_xi = []

    for i in range(len(lista_resultados)):
        lista_xi.append(lista_resultados[i][0])

    return lista_xi



def extraer_errores(lista_resultados):
    lista_xi = []

    for i in range(len(lista_resultados)):
        lista_xi.append(lista_resultados[i][1])

    return lista_xi

"""###### *1.1.1.5.3 Funci√≥n auxiliar para representar los valores en tablas*"""

def lista_resultados_a_dataframe(lista_resultados,lista_alfa,lista_cte_asintotica,columnas):
    lista_auxiliar = lista_resultados   
    for i in range(len(lista_auxiliar)):
        lista_auxiliar[i].append(lista_alfa[i])
        lista_auxiliar[i].append(lista_cte_asintotica[i])
    df = pd.DataFrame(lista_auxiliar, columns=columnas)
    if len(df) > 12:
        return pd.concat([df.head(), df.tail()])
    else:
        return df

"""###### 1.1.1.5.4 Extracci√≥n de valor obtenido en ultima iteraci√≥n: $p_n$ """

def extraer_ultimo_pn_biseccion(lista_resultados):
    posicion_ultimo_elemento = len(lista_resultados)-1

    ultimo_elemento = lista_resultados[posicion_ultimo_elemento][2] 

    return ultimo_elemento


def extraer_ultimo_pn(lista_resultados):
    posicion_ultimo_elemento = len(lista_resultados)-1

    ultimo_elemento = lista_resultados[posicion_ultimo_elemento][0] 

    return ultimo_elemento

"""#### 1.1.1.6 Criterios de paro:
En general utilizamos el criterio de paro $ |p_n  - p_{n-1}| \leq œµ$; con $œµ = tolerancia$

A su vez tambien consideramos diversos casos de error o advertencias a lo largo de los algoritmos, como son:
- Divergencia de m√©todos (por lo tanto el error entre iteraciones es creciente).
- El valor aproximado de una ra√≠z devuelto por el m√©todo en dos iteraciones consecutivas fue el mismo (por lo cual el error deja de ser representable)
- Se llega a una cantidad m√°xima de iteraciones antes de cumplir con la tolerancia pedida.

### **1.1.2 Metodo de la biseccion**

Su implementaci√≥n se basa en que si $f \in C[a,b] $ y $f(a) ‚ãÖ f(b) < 0$ ; el teor√©ma de Bolzano garantiza que existe $p \in (a,b)$ tal que $f(p) = 0$

Con esto se va dividiendo en subintervalos del intervalo $[a,b]$  y en cada paso se determina en qu√© subintervalo se encuentra la ra√≠z usando el mismo razonamiento; repitiendo hasta que se llegue a los distintos criterios de paro.

(Tener en cuenta entonces que para el correcto funcionamiento del m√©todo se debe garantizar que $f(a) ‚ãÖ f(b) < 0$)
"""

def biseccion_recursivo(funcion, numero_iteracion, an, bn, tolerancia, lista_resultados):
    if(MAX_ITERACIONES == numero_iteracion):
        print(ERROR_MAX_ITERACIONES) 
        return lista_resultados,False 

    pn = (an+bn)/2 
    error_actual = np.abs((bn-an)/2)
    lista_resultados_n = [an, bn, pn, error_actual]  #[an, bn, pn, error]  
    lista_resultados.append(lista_resultados_n)
                            
    if((error_actual < tolerancia) or (isclose(funcion(pn), 0))):
        return lista_resultados, True

    if(funcion(an) * funcion (pn) > 0):
        an = pn
    elif(funcion(bn) * funcion (pn) > 0):
        bn = pn

    return biseccion_recursivo(funcion, numero_iteracion+1, an, bn, tolerancia, lista_resultados) 


def biseccion(funcion, an, bn, tolerancia): 
    lista_resultados = []
    numero_de_iteracion = 0
    
    if((an >= bn) or (tolerancia <= 0) or (MAX_ITERACIONES <= 0)):
        print(ERROR_EJECUCION)
        return None, False

    return biseccion_recursivo(funcion, numero_de_iteracion, an, bn, tolerancia, lista_resultados)

"""#### Ejemplo de uso"""

f = lambda x:  x - np.e**-x
a0 = 0.1
b0 = 1

lista_resultados_biseccion = biseccion(f, a0, b0, tolerancia=1e-06)[0]
lista_pn_biseccion = extraer_pn_biseccion(lista_resultados_biseccion)
lista_errores_biseccion = extraer_errores_biseccion(lista_resultados_biseccion)
lista_alfa_biseccion = calcular_orden_de_convergencia_alfa(lista_pn_biseccion)
lista_cte_asintotica_biseccion = calcular_cte_asintotica_lambda(lista_errores_biseccion, lista_alfa_biseccion)



lista_resultados_a_dataframe(lista_resultados_biseccion,lista_alfa_biseccion,lista_cte_asintotica_biseccion,['an', 'bn', 'pn', 'error','alfa','lambda'])

"""### **1.1.3 Metodo Punto Fijo**

Su implementaci√≥n se basa en el uso de una funci√≥n $g(x)$ de iteraci√≥n funcional, tal que 
$g(x) = x - f(x) $ ;

con $ùùã(x) = 1$ para √©ste m√©todo

Esto viene de que:
 
Queremos analizar el valor de la ra√≠z de una $f \in C[a,b] $,
estamos buscando  $p \in (a,b)$ tal que $f(p) = 0$;

A su vez, sea una funci√≥n $g \in C[a,b] $, se dice que la misma tiene punto fijo  $p \in [a,b]$ si $g(p) = p$;

Por lo tanto si se define $g(x) = x - f(x) $  y $p$ es punto fijo de $g$:

$g(p) = p = p - f(p)$

 $‚áí$ $f(p) = p - p = 0$

Con lo cual hallar el punto fijo de $g$ es equivalente a hallar la ra√≠z buscada de $f$

(Tener en cuenta entonces que para el correcto funcionamiento del m√©todo se debe garantizar que:
- Existe punto fijo para $g$ en el intervalo:
    
    Debe cumplirse que  $g \in C[a,b] $  y  $g(x) \in [a,b]$ $\forall$ $x \in [a,b]$
- El punto fijo es √∫nico para $g$ en el intervalo:
    
    Debe cumplirse que  $‚àÉ$ $g'(x)$ $\forall$ $x \in (a,b)$  y que  $‚àÉ$ $0 < k < 1$ tal que $\forall$ $x \in (a,b)$ vale que $|g'(x)| \leq k$

)
"""

def metodo_punto_fijo(funcion, p0, tolerancia):
    lista_resultados = []
    numero_iteracion = 0
    g = lambda x: x - funcion(x)

    if((tolerancia <= 0) or (MAX_ITERACIONES <= 0)):
        return None, False
        
    lista_resultados.append([p0, None])

    return iteracion_funcional_recursiva(g, numero_iteracion+1, tolerancia, lista_resultados)

"""#### Ejemplo de uso"""

f = lambda x:  x - np.e**-x
semilla_p0 = 0.55

lista_resultados_punto_fijo = metodo_punto_fijo(f, semilla_p0, tolerancia=1e-06)[0]
lista_pn_punto_fijo = extraer_pn(lista_resultados_punto_fijo)
lista_alfa_punto_fijo = calcular_orden_de_convergencia_alfa(lista_pn_punto_fijo)
lista_errores_punto_fijo = extraer_errores(lista_resultados_punto_fijo)
lista_cte_asintotica_punto_fijo = calcular_cte_asintotica_lambda(lista_errores_punto_fijo, lista_alfa_punto_fijo)

lista_resultados_a_dataframe(lista_resultados_punto_fijo,lista_alfa_punto_fijo,lista_cte_asintotica_punto_fijo,columnas=['pn', 'error','alfa','lambda'])

"""### **1.1.4 Metodo Newton-Raphson**

Su implementaci√≥n se basa en el uso de una funci√≥n $g(x)$ de iteraci√≥n funcional, tal que 
$g(x) = x - \frac{f(x)}{f'(x)} $ ;

con $ùùã(x) = \frac{1}{f'(x)}$ para √©ste m√©todo

Esto viene de que:
 
Se realiza su deducci√≥n a partir del polinomio de taylor, tomando una aproximaci√≥n de la ra√≠z $p$ de tal forma que la distancia de dicha aproximaci√≥n a la ra√≠z real sea cercana a cero.

En base a esta "cercan√≠a" se puede deducir que el cumplimiento de las hip√≥tesis de punto fijo se satisfacen bajo dicha condici√≥n.

(Tener en cuenta entonces que para el correcto funcionamiento del m√©todo se debe garantizar que:
- La semilla o aproximaci√≥n inicial debe ser elegida en un intervalo tal que se le considere suficientemente a la ra√≠z esperada.
- Debe cumplirse que  $f \in C^2[a,b] $  y  $f'(x)$ no debe anularse en el entorno inicial que se elija para contener a la semilla y a la ra√≠z

)
"""

def metodo_newton_raphson(funcion, derivada_funcion, p0, tolerancia):
    lista_resultados = []
    numero_iteracion = 0
    g = lambda x: x - funcion(x)/derivada_funcion(x)

    if((tolerancia <= 0) or (MAX_ITERACIONES <= 0)):
        return ERROR_EJECUCION

    lista_resultados.append([p0, None])

    return iteracion_funcional_recursiva(g, numero_iteracion+1, tolerancia, lista_resultados)

"""#### Ejemplo de uso"""

f = lambda x:  x - np.e**-x
derivada_f = lambda x:  1 + np.e**-x
semilla_p0 = 0.55

lista_resultados_NR = metodo_newton_raphson(f, derivada_f, semilla_p0, tolerancia=1e-06)[0]
lista_pn_NR = extraer_pn(lista_resultados_NR)
lista_alfa_NR = calcular_orden_de_convergencia_alfa(lista_pn_NR)
lista_errores_NR = extraer_errores(lista_resultados_NR)
lista_cte_asintotica_NR = calcular_cte_asintotica_lambda(lista_errores_NR, lista_alfa_NR)

lista_resultados_a_dataframe(lista_resultados_NR,lista_alfa_NR,lista_cte_asintotica_NR,['pn', 'error','alfa','lambda'])

"""### **1.1.5 Metodo Newton-Raphson modificado para raices multiples**

Su implementaci√≥n se basa en el uso de una funci√≥n $g(x)$ de iteraci√≥n funcional, tal que 
$g(x) = x - \frac{f(x)‚ãÖf'(x)}{f'(x)^2 - f(x)‚ãÖf''(x)} $ ;

con $ùùã(x) = \frac{f'(x)}{f'(x)^2 - f(x)‚ãÖf''(x)}$ para √©ste m√©todo

Esto viene de que:
 
Se realiza la modificaci√≥n a partir de ver que al aplicar NR sin modificar para raices de multiplicidad algebr√°ica $m > 1,$ hace que se pierda la convergencia cuadr√°tica del m√©todo, con lo cual se modifica teniendo en cuenta que:

$f \in C^m[a,b] $  tiene un cero de multiplicidad algebr√°ica $m$ en $p \in (a,b)$ $‚áî$ $0 = f(p) = f'(p) = f''(p) = ‚ãØ = f^{(m-1)}(p)$ y $f^{(m)}(p) \neq 0$

(Tener en cuenta entonces que para el correcto funcionamiento del m√©todo se deben garantizar las mismas condiciones mencionadas para Newton-Raphson)
"""

def metodo_newton_raphson_para_raices_multiples(funcion, derivadaFuncion, derivadaSegundaFuncion, p0, tolerancia):
    lista_resultados = []
    numero_iteracion = 0
    g = lambda x: x - (funcion(x)*derivadaFuncion(x))/(derivadaFuncion(x)**2 - funcion(x)*derivadaSegundaFuncion(x))

    if((tolerancia <= 0) or (MAX_ITERACIONES <= 0)):
        return None, False

    lista_resultados.append([p0, None])

    return iteracion_funcional_recursiva(g, numero_iteracion+1, tolerancia, lista_resultados)

"""#### Ejemplo de uso"""

f = lambda x:  x - np.e**-x
derivada_f = lambda x:  1 + np.e**-x
derivada_segunda_f = lambda x:  -np.e**-x
semilla_p0 = 0.55

lista_resultados_NR_multiple = metodo_newton_raphson_para_raices_multiples(f, derivada_f, derivada_segunda_f, semilla_p0, tolerancia=1e-06)[0]
lista_pn_NR_multiple = extraer_pn(lista_resultados_NR_multiple)
lista_alfa_NR_multiple = calcular_orden_de_convergencia_alfa(lista_pn_NR_multiple)
lista_errores_NR_multiple = extraer_errores(lista_resultados_NR_multiple)
lista_cte_asintotica_NR_multiple = calcular_cte_asintotica_lambda(lista_errores_NR_multiple, lista_alfa_NR_multiple)

lista_resultados_a_dataframe(lista_resultados_NR_multiple,lista_alfa_NR_multiple,lista_cte_asintotica_NR_multiple,['pn', 'error','alfa','lambda'])

"""### **1.1.6 Metodo Secante**

Su implementaci√≥n se basa en el uso de una funci√≥n $g(x)$ de iteraci√≥n funcional, tal que 
$g(x,y) = x - \frac{f(x)‚ãÖ(x-y)}{f(x) - f(y)} $ ;

con $ùùã(x,y) = \frac{(x-y)}{f(x) - f(y)}$ para √©ste m√©todo

(Para mayor claridad, se muestra la sucesi√≥n como:
    $p_{n} = p_{n-1} - \frac{f(p_{n-1})‚ãÖ(p_{n-1}-p_{n-2})}{f(p_{n-1}) - f(p_{n-2})}$
)

Esto viene de que:

Se usa la definici√≥n de derivada con el cociente incremental para llegar a una aproximaci√≥n que permite evitar la evaluaci√≥n de $f'$ proveniente del m√©todo de NR.

(Tener en cuenta que, a pesar de que se usa una aproximaci√≥n de los valores de la derivada, para el correcto funcionamiento del m√©todo se deben garantizar las mismas condiciones mencionadas para Newton-Raphson. Adem√°s de esto ahora se debe contar con **dos semillas** o aproximaciones iniciales cercanas a la ra√≠z buscada)
"""

def metodo_secante(funcion, p0, p1, tolerancia):
    lista_resultados = []
    numero_iteracion = 0
    g = lambda x,y: x - (funcion(x)*(x-y))/(funcion(x)-funcion(y))

    if((tolerancia <= 0) or (MAX_ITERACIONES <= 0)):
        return ERROR_EJECUCION

    lista_resultados.append([p0, None])
    lista_resultados.append([p1, None])
    
    return iteracion_funcional_recursiva_de_dos_semillas(g, numero_iteracion+2, tolerancia, lista_resultados)

"""#### Ejemplo de uso"""

f = lambda x:  x - np.e**-x
semilla_p0 = 0
semilla_p1 = 5

lista_resultados_secante = metodo_secante(f, semilla_p0, semilla_p1, tolerancia=1e-06)[0]
lista_pn_secante = extraer_pn(lista_resultados_secante)
lista_alfa_secante = calcular_orden_de_convergencia_alfa(lista_pn_secante)
lista_errores_secante = extraer_errores(lista_resultados_secante)
lista_cte_asintotica_secante = calcular_cte_asintotica_lambda(lista_errores_secante, lista_alfa_secante)

lista_resultados_a_dataframe(lista_resultados_secante,lista_alfa_secante,lista_cte_asintotica_secante,['pn', 'error','alfa','lambda'])

"""## ***1.2 Planteo del problema***

###1.2.1 (Pregunta $a$) Formule el problema y graf√≠quelo.

____________________________________________________________________________
 **Datos del problema:**
 - $827$ $kg$ es el minimo de mercaderia para justificar el setup de las maquinas.
 - $\$25000$ es el ingreso minimo que se desea obtener.
____________________________________________________________________________

Se tiene que la utilidad unitaria corresponde a la expresi√≥n:

  $u(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2$

Por lo tanto para cumplir con la contribucion minima que se solicita $(\$25000)$ se busca analizar las cantidades de producto correspondiente al proponer:

 $\$25000 \leq u(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2$

$‚áí$ $0 \leq 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

Por lo tanto con el fin de buscar la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y justificaci√≥n del setup de las m√°quinas, plantearemos la siguiente funci√≥n a analizar:

 $f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

Dado que para justificar el setup de las m√°quinas se necesitan al menos $827$ $kg$ $‚áí$ $x \geq 827$ $kg$ 

En resumen, buscamos el $x_{min}$ tal que $f(x_{min}) \geq 0 $  ‚Äé ‚Äé $,$ ‚Äé‚Äé ‚Äé ‚Äé $x_{min} \geq 827$ $kg$

A continuaci√≥n realizaremos un an√°lisis gr√°fico de $f(x)$


La funci√≥n anteriormente planteada es una funci√≥n cubica, por lo cual tendr√° un m√°ximo de 3 raices.
"""

MIN_CONTRIBUCION_MENSUAL = 25000

def utilidad_unitaria (x):
  return 0.001*x*((x-1000)**2)

def f(x):
  return utilidad_unitaria(x)-MIN_CONTRIBUCION_MENSUAL

intervalo = np.linspace(-50,1400,1000)
func = f(intervalo)

fig, ax = plt.subplots(figsize=(10, 10))

plt.title("Grafica  f(x) vs x ")
plt.xlabel("Cantidad de producto (x) [kg]")
plt.ylabel("f(x) [$]")

plt.plot(intervalo, func, label = 'f(x)', color = 'blue', linewidth= 2)

plt.plot([-200,1400],[0,0], label = 'ejes', color = 'black')
plt.plot([0,0],[-50000, 130000], color = 'black')
plt.plot([827,827],[-50000, 130000], label = 'x = 827 [kg]', color = 'red', linestyle='--')


ax.set_xlim(-200, 1400)
ax.set_ylim(-50000, 130000)

ax.xaxis.set_major_locator(MultipleLocator(100))

ax.grid()

plt.legend()
plt.show()

"""____________________________________________________________________________
  **Informaci√≥n actual**:
  - $f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$
  - Buscamos el $x_{min}$ tal que $f(x_{min}) \geq 0 $  ‚Äé ‚Äé $,$ ‚Äé‚Äé ‚Äé ‚Äé $x_{min} \geq 827$ $kg$
____________________________________________________________________________

Se observa que la funci√≥n posee tres raices:
- $(1)$ Acotada en intervalo $x$ $\in$ $[0,100]$
- $(2)$ Acotada en intervalo $x$ $\in$ $[800,900]$
- $(3)$ Acotada en intervalo $x$ $\in$ $[1100,1200]$


 **An√°lisis de ra√≠ces**:

- *An√°lisis ra√≠z $(1)$*: 

    A partir de las tres ra√≠ces podemos descartar el an√°lisis de la ra√≠z $(1)$ m√°s cercana a $x=0$ dado que la misma se puede acotar en el intervalo $[0,100]$, lo cu√°l implica que √©sta cantidad de producto no justifica el setup de las m√°quinas (siempre se cumple que esa cantidad es menor a $827$ $kg$). 

- *An√°lisis ra√≠z $(2)$*: 

    Dado que debe cumplirse $x \geq 827$ $kg$, tomaremos el intervalo $[827,900]$ y verificaremos el comportamiento de la funci√≥n en dicho intervalo para saber si all√≠ existe una ra√≠z ya que con el an√°lisis gr√°fico no tenemos suficiente certeza:
    - Tomamos un $x$ $\in$ $[827,900]$
    - $‚áí 827 \leq x \leq 900 $
    - $‚áí -173 \leq x - 1000 \leq -100 $
    - $‚áí 29929 \leq (x - 1000)^2 \leq 10000 $
    - $‚áí 0.001‚ãÖ29929 \leq 0.001‚ãÖ(x - 1000)^2 \leq 0.001‚ãÖ10000 $
    - $‚áí 827‚ãÖ(0.001‚ãÖ29929) \leq x‚ãÖ(0.001‚ãÖ29929) \leq 0.001‚ãÖx‚ãÖ(x - 1000)^2$ $;$
      $ 80.001‚ãÖx‚ãÖ(x - 1000)^2  \leq x‚ãÖ(0.001‚ãÖ10000) \leq 900‚ãÖ(0.001‚ãÖ10000) $
    - $‚áí 827‚ãÖ(0.001‚ãÖ29929) \leq 0.001‚ãÖx‚ãÖ(x - 1000)^2 \leq 900‚ãÖ(0.001‚ãÖ10000) $
    - $‚áí 827‚ãÖ(0.001‚ãÖ29929)-25000 \leq 0.001‚ãÖx‚ãÖ(x - 1000)^2 - 25000 \leq 900‚ãÖ(0.001‚ãÖ10000) - 250000 $
    - $‚áí 827‚ãÖ0.001‚ãÖ29929-25000 \leq 0.001‚ãÖx‚ãÖ(x - 1000)^2 - 25000 \leq 900‚ãÖ0.001‚ãÖ10000 - 250000 $
    - $‚áí -248.717 \leq 0.001‚ãÖx‚ãÖ(x - 1000)^2 - 25000 \leq -16000 $
    - $‚áí -248.717 \leq f(x) \leq -16000 $
    - $‚áí f(x) \leq 0$ $‚àÄ$ $x$ $\in$ $[827,900]$

    Teniendo esto en cuenta, determinamos que no se cumple una de las restricciones pedidas ($f(x) \geq 0 $) y adem√°s no existe ninguna raiz dentro de ese intervalo. 

    Dado que la raiz $x \in [800,900], x \notin [800,900] ‚áí x \in [800,827)$, lo cual conlleva que que la raiz $(2)$ tambien sea descartada siendo que la cantidad de producto no justifica el setup de las m√°quinas (siempre se cumple que esa cantidad es menor a $827$ $kg$). 

- *An√°lisis ra√≠z $(3)$*: 

    En cuanto a la ra√≠z restante procederemos a aplicar los m√©todos de b√∫squeda de ra√≠ces siendo que no se puede acotar visualmente para conocer su valor y asi obtener la cantidad m√≠nima de producto a generar.

### 1.2.2 (Pregunta $b$) Hallar las cantidades a fabricar del producto ‚ÄúE41‚Äù utilizando los m√©todos vistos en clase:
### Bisecci√≥n, Punto Fijo, Newton-Raphson, Newton-Raphson modificado y Secante.
### Use para todos los m√©todos como criterio de parada las siguientes cotas:
### $1 ¬∑ 10^{‚àí5}$ y $1 ¬∑ 10^{‚àí13}$, use como semilla un valor tomado con el criterio que considere correcto, justificar.

#### **1.2.2.1 Bisecci√≥n/ Busqueda Binaria / Metodo de Arranque:**

##### *Definiciones previas*

$f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

##### *Verificaci√≥n de la convergencia del m√©todo*

A partir del Teorema de Bolzano o Teorema del valor medio es que demostramos la existencia de al menos una raiz dentro del intervalo $[1100,1200]$:

Dado que $f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1100kg)^2 - \$25000$ es un polinomio de grado 3, sabemos que $f \in  C[1100;1200]$. 

A su vez, verificamos que $f(1100) ‚ãÖ f(1200) < 0$ que junto al analisis grafico anterior nos permite confirmar la existencia de una √∫nica raiz en dicho intervalo.

##### *Aplicaci√≥n del m√©todo* 
Tras realizar la comprobaci√≥n de las hipotesis mencionadas aplicamos el metodo de bisecci√≥n.
"""

f(1200)*f(1100) < 0

lista_resultados_biseccion_cota_1, encontrado_biseccion_cota_1 = biseccion(f, 1100,1200, tolerancia=COTA_DE_ERROR_1)

extraer_ultimo_pn_biseccion(lista_resultados_biseccion_cota_1)

"""Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-5}$ es: 

$x = [1147.59629 \pm 0.00001]kg$

"""

lista_resultados_biseccion_cota_2, encontrado_biseccion_cota_2 = biseccion(f, 1100,1200, tolerancia=COTA_DE_ERROR_2)

extraer_ultimo_pn_biseccion(lista_resultados_biseccion_cota_2)

"""Si bien no se encontr√≥ un valor con tolerancia $1\cdot10^{-13}$ se puede proponer el valor de la √∫ltima iteraci√≥n del m√©todo: 

$x = [1147.5962886 \pm 0.0000001] kg$

(Valor del error obtenido de tabla de resultados)

#### **1.2.2.2 M√©todo del Punto Fijo:**

##### *Definiciones previas*

Siendo que buscamos las raices de la funcion $f(x)$, es decir, $f(x) = 0$, propongo una funci√≥n $g(x) = x - f(x)$ a la cual le aplicar√© el metodo del punto fijo. Esto es porque suponiendo que la raiz de $f(x)$ sea el valor $p ‚áí g(p) = p - f(p) ‚áí g(p) = p - 0$ ‚áí $g(p) = p$

Definimos $g(x) = x - f(x) = x - 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

##### *Verificaci√≥n de la convergencia del m√©todo*

Verificamos existencia y unicidad de la raiz en en intervalo cerrado $[1100,1200]$. 
Para ello se deben cumplir las siguientes condiciones:
1.   Si $g(x) ‚àà C[1100,1200]$ y $g(x) ‚àà [1100,1200]$ $‚àÄ$ $x ‚àà [1100,1200]$ ‚áí existe al menos un punto fijo dentro del intervalo $[1100,1200]$
2.   Si $‚àÉ$ $g'(x)$ $‚àÄ$  $x ‚àà (1100,1200)$ y $|g'(x)| ‚â§ k$ $‚àÄ$  $x ‚àà (1100,1200)$ donde $0 < k < 1$ ‚áí el punto fijo es √∫nico dentro del intervalo $[1100,1200]$

En caso de cumplir con ambas condiciones, la funcion $g(x)$ es admisible y por lo tanto (por teorema visto en clase), $‚àÄ$ $p_0 \in [1100,1200]$ la sucesi√≥n definida como $p_n = g(p_{n-1})$ converge al √∫nico punto fijo de $g(x)$.

###### *Verifico condici√≥n 1:*

Dado que $g(x) = x - f(x)$ y $f(x) ‚àà C[1100,1200]$ por ser un polinomio de grado 3 ‚áí $g(x) ‚àà C[1100,1200]$ por ser suma de funciones $‚àà C[1100,1200]$.

A continuacion verificaremos gr√°ficamente si se cumple que $g(x) ‚àà [1100,1200]$ $‚àÄ$ $x ‚àà [1100,1200]$ (Condici√≥n 1):
"""

def g(x,funcion):
  return x-funcion(x)

intervalo = np.linspace(-100,1400,1000)
func = g(intervalo,f)

fig, ax = plt.subplots(figsize=(10, 10))

plt.title("Grafica funci√≥n g(x)")
plt.xlabel("x")
plt.ylabel("y")

plt.plot(intervalo, func, label = 'g(x)', color = 'blue', linewidth= 2)

plt.plot([-200,1400],[0,0], label = 'ejes', color = 'black')
plt.plot([0,0],[-50000, 130000], color = 'black')

plt.plot([1100,1200],[1100,1100], label = 'Condici√≥n 1', color = 'red', linestyle='--')
plt.plot([1100,1200],[1200,1200], color = 'red', linestyle='--')
plt.plot([1100,1100],[1100,1200], color = 'red', linestyle='--')
plt.plot([1200,1200],[1100,1200], color = 'red', linestyle='--')

ax.set_xlim(-100, 1400)
ax.set_ylim(-100, 1400)

ax.xaxis.set_major_locator(MultipleLocator(100))
ax.yaxis.set_major_locator(MultipleLocator(100))

ax.grid()
plt.legend(loc = 'best')
plt.show()

"""Podemos concluir al mirar el gr√°fico que la condici√≥n $g(x) ‚àà [1100,1200]$ para cualquier $x ‚àà [1100,1200]$ no se cumple, ya que la funci√≥n cruza las lineas rojas tanto superiormente como inferiormente. En caso de cumplirse la condici√≥n, la funci√≥n deberia cruzar por las lineas laterales. 

Esto implica que no se puede asegurar la existencia de un punto fijo dentro de dicho intevalo.

###### *Verifico condici√≥n 2:*

Siendo que no podemos asegurar la existencia de un punto fijo dentro del intervalo $[1100,1200]$ mediante la condicion 1, ya no se cumple que la funci√≥n $g(x)$ sea admisible.

Sin embargo, verificaremos de todas formas si se cumple la segunda condici√≥n:

Dado que $g(x) = x - 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$, entonces 
$g'(x) = 1 - 0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 - 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg)$
"""

def g_derivada(x):
  return 1-0.001*((x-1000)**2)-2*0.001*x*(x-1000)

intervalo = np.linspace(950,1250,100)
func = g_derivada(intervalo)

fig, ax = plt.subplots(figsize=(10, 10))

plt.title("Grafica funci√≥n g'(x)")
plt.xlabel("x")
plt.ylabel("y")

plt.plot(intervalo, func, label = "g'(x)", color = 'blue', linewidth= 2)
plt.plot([950,1250],[0,0],"black")
plt.plot([950,1250],[1,1], label = 'y =  1', color = 'red', linestyle='--')
plt.plot([950,1250],[-1,-1], label = 'y = -1', color = 'red', linestyle='--')

plt.plot([1100,1100],[-10,10], label = 'x = 1100 [kg]', color = 'grey', linestyle='--', linewidth= 2)
plt.plot([1200,1200],[-10,10], label = 'x = 1200 [kg]', color = 'grey', linestyle='--', linewidth= 2)

ax.set_xlim(950, 1250)
ax.set_ylim(-10, 10)

ax.yaxis.set_major_locator(MultipleLocator(1))

plt.grid()
plt.legend()
plt.show()

"""$g(x)$ tampoco cumple con la condici√≥n 2: $|g'(x)| ‚â§ k$ con $0 < k < 1$ en el intervalo $[1100;1200]$.

##### *Aplicaci√≥n del m√©todo* 

Pese a saber que el m√©todo no converge bajo estas condiciones, se muestra que al intentar obtener la raiz se llega al maximo de iteraciones permitidas:

La semilla $p_0$ se obtiene a partir de la primer iteracion del m√©todo de la biseccion, en donde anteriormente se demostr√≥ que dicho m√©todo converger√° a la raiz.

Tomando el intervalo $[1100, 1200]$ ‚áí $p_0 = \frac{(a + b)}{2} = \frac{(1100 \cdot kg + 1200 \cdot kg)}{2} = 1150 kg$
"""

semilla_p0 = 1150

lista_resultados_punto_fijo_cota_1, encontrado_punto_fijo_cota_1 = metodo_punto_fijo(f, semilla_p0, tolerancia=COTA_DE_ERROR_1)

lista_resultados_punto_fijo_cota_2, encontrado_punto_fijo_cota_2 = metodo_punto_fijo(f, semilla_p0, tolerancia=COTA_DE_ERROR_2)

"""Dado que no se cumplieron las hip√≥tesis para aplicar el m√©todo, se corrobora que diverge para ambas cotas de error y por lo tanto no se puede obtener el valor de cantidad de producto m√≠nimo correspondiente.

#### **1.2.2.3 M√©todo de Newton-Raphson:**

##### *Definiciones previas*

$f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

##### *Verificaci√≥n de la convergencia del m√©todo*

A partir del teorema visto en clase que se citar√° a continuacion, verificarmemos si se puede asegurar la convergencia de este m√©todo:

Sea $f \in C^2[a,b]$. Si $p \in [a,b]$ tal que $f(p) = 0$ y $f'(p) \neq 0$ entonces $‚àÉ$ $ùõÖ > 0$ tal que el m√©todo de Newton-Raphson genera una sucesi√≥n : { ${p_n}$ }$_{n \geq 1}$ que converge a $p$ para cualquier aproximaci√≥n inicial $p_0 \in [p-ùõÖ, p+ùõÖ]$ 

Dado que $f$ es un polinomio de grado 3 $‚áí$ $f \in C^2[1100,1200]$

Derivo $f$ para verificar que no se anule la derivada en dicho intervalo:

$f'(x) = 0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg)$
"""

def f_derivada_primera(x):
  return 0.001*((x-1000)**2)+2*0.001*x*(x-1000)

intervalo = np.linspace(1050,1250,100)
derivada = f_derivada_primera(intervalo)

fig, ax = plt.subplots(figsize=(10, 10))

plt.title("Grafica funci√≥n f'(x)")
plt.xlabel("x")
plt.ylabel("y")

plt.plot(intervalo, derivada, label = "f'(x)", color = 'blue', linewidth= 2)

plt.plot([1050,1250],[0,0], label = 'eje x', color = 'black')

plt.plot([1100,1100],[-300,600], label = 'x = 1100 [kg]', color = 'grey', linestyle='--', linewidth= 2)
plt.plot([1200,1200],[-300,600], label = 'x = 1200 [kg]', color = 'grey', linestyle='--', linewidth= 2)

ax.set_xlim(1050, 1250)
ax.set_ylim(-300, 600)

plt.grid()
plt.legend(loc = 'best')
plt.show()

"""Como podemos observar en el gr√°fico, $f'(x) \neq 0$ $‚àÄ$ $x \in [1100, 1200]$, lo cual implica que el m√©todo converge a la raiz dentro de dicho intervalo.

##### *Aplicaci√≥n del m√©todo* 

La semilla $p_0$ se obtiene a partir de la primer iteracion del m√©todo de la biseccion, en donde anteriormente se demostr√≥ que dicho m√©todo converger√° a la raiz.

Tomando el intervalo $[1100, 1200]$ ‚áí $p_0 = \frac{(a + b)}{2} = \frac{(1100 \cdot kg + 1200 \cdot kg)}{2} = 1150 kg$
"""

semilla_p0 = 1150
lista_resultados_NR_cota_1, encontrado_NR_cota_1 = metodo_newton_raphson(f, f_derivada_primera, semilla_p0, tolerancia=COTA_DE_ERROR_1)

extraer_ultimo_pn(lista_resultados_NR_cota_1)

"""Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-5}$ es: 

$x = [1147.59629 \pm 0.00001]kg$

"""

lista_resultados_NR_cota_2, encontrado_NR_cota_2 = metodo_newton_raphson(f, f_derivada_primera, semilla_p0, tolerancia=COTA_DE_ERROR_2)

extraer_ultimo_pn(lista_resultados_NR_cota_2)

"""Dado que el error entre dos iteraciones result√≥ $|p_n - p_{n-1}| = 0$, no hubo diferencia entre el valor de las aproximaciones consecutivas de la ra√≠z.
Esto se puede explicar debido a la cantidad de digitos significativos con la que trabaja la computadora, por lo cual concluimos que:

Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-12}$ es: 

$x = [1147.596288534586 \pm 10^{-12}]kg$

#### **1.2.2.4 M√©todo de Newton-Raphson modificado:**

##### *Definiciones previas*

$f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$ 

$f'(x) = 0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg)$

##### *Verificaci√≥n de la convergencia del m√©todo*

A partir del analsis realizado para el m√©todo de Newton-Raphson:

Dado que $f$ es un polinomio de grado 3 $‚áí$ $f \in C^2[1100,1200]$

$ f(x) = 0$ $‚àÄ$ $x \in [1100, 1200]$, 

$f'(x) \neq 0$ $‚àÄ$ $x \in [1100, 1200]$

Podemos concluir que $f$ tiene un cero simple en el intervalo $[1100, 1200]$

Dado que la multiplicidad de la ra√≠z de $f$ no modifica la convergencia cuadr√°tica que posee el m√©todo, solo resta indicar que la funcion $g$ definida de la siguiente manera, es continua:

$g(x) = x - \frac{f(x) \cdot f'(x)}{[f'(x)]^2 - f(x) ‚ãÖ f''(x)}$

Defino: $œï(x) = \frac{f(x) \cdot f'(x)}{[f'(x)]^2 - f(x) ‚ãÖ f''(x)}$

$‚áí g(x) = x - œï(x)$

Por lo tanto debemos verificar que la funcion $œï$ sea continua dentro del intervalo $[1100, 1200]$.

Para verificar la continuidad de $œï$ debo ver en que punto se anula la expresion: $[f'(x)]^2 - f(x) ‚ãÖ f''(x)$ ya que el numerador de $œï(x) = \frac{f(x) \cdot f'(x)}{[f'(x)]^2 - f(x) ‚ãÖ f''(x)}$ es una funcion continua, dado que $f$ es un polinomio de grado (multiplicacion de funciones continuas da como resultado una funcion continua).

Busco $f''(x)$:

$f'(x) = 0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg)$

$f''(x) = 2 ‚ãÖ 0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg) + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ (x‚àí1000kg) + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x $

$f''(x) = 2 ‚ãÖ 0,001\frac{$}{kg^3} ¬∑ [2 \cdot (x‚àí1000kg) +  x ]$

$f''(x) = 2 ‚ãÖ 0,001\frac{$}{kg^3} ¬∑ (3x‚àí2000kg)$

$f''(x) = 0.006\frac{$}{kg^3} ¬∑ x ‚àí 4 \frac{$}{kg^2} $

Grafico la funcion $Œ±(x) = [f'(x)]^2 - f(x) ‚ãÖ f''(x)$  en el intervalo $[1100, 1200]$ para ver si posee raices:

$Œ±(x) = [0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg)] ^ 2 - (0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000) ‚ãÖ (0,001\frac{$}{kg^3} ¬∑(x‚àí1000kg)^2 + 2 \cdot 0,001\frac{$}{kg^3} ‚ãÖ x ‚ãÖ (x‚àí1000kg))$
"""

def f_derivada_segunda(x):
  return 0.006*x - 4

def alpha(f, f_derivada_primera, f_derivada_segunda, x):
    return ((f_derivada_primera(x)) ** 2) - (f(x) * f_derivada_segunda(x))

intervalo = np.linspace(1050,1250,100)
func = alpha(f, f_derivada_primera, f_derivada_segunda, intervalo)

fig, ax = plt.subplots(figsize=(10, 10))

plt.title("Grafica funci√≥n f'(x)")
plt.xlabel("x")
plt.ylabel("y")

plt.plot(intervalo, func, label = "$Œ±(x)$", color = 'blue', linewidth= 2)

plt.plot([1050,1250],[0,0], label = 'eje x', color = 'black')

plt.plot([1100,1100],[-25000,200000], label = 'x = 1100 [kg]', color = 'grey', linestyle='--', linewidth= 2)
plt.plot([1200,1200],[-25000,200000], label = 'x = 1200 [kg]', color = 'grey', linestyle='--', linewidth= 2)

ax.set_xlim(1050, 1250)
ax.set_ylim(-25000, 200000)

plt.grid()
plt.legend(loc = 'best')
plt.show()

"""Dado que la funcion $Œ±$ no contiene raices en el intervalo $[1100, 1200]$ $‚áí œï$ es continua dentro de dicho intervalo $‚áí g$ es continua dentro de dicho intervalo.

Esto implica que la convergencia de este m√©todo esta asegurada y ademas es cuadr√°tica.

##### *Aplicaci√≥n del m√©todo* 

La semilla $p_0$ se obtiene a partir de la primer iteracion del m√©todo de la biseccion, en donde anteriormente se demostr√≥ que dicho m√©todo converger√° a la raiz.

Tomando el intervalo $[1100, 1200]$ ‚áí $p_0 = \frac{(a + b)}{2} = \frac{(1100 \cdot kg + 1200 \cdot kg)}{2} = 1150 kg$
"""

semilla_p0 = 1150

lista_resultados_NR_multiple_cota_1, encontrado_NR_multiple_cota_1 = metodo_newton_raphson_para_raices_multiples(f, f_derivada_primera, f_derivada_segunda, semilla_p0, tolerancia=COTA_DE_ERROR_1)

extraer_ultimo_pn(lista_resultados_NR_multiple_cota_1)

"""Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-5}$ es: 

$x = [1147.59629 \pm 0.00001]kg$

"""

lista_resultados_NR_multiple_cota_2, encontrado_NR_multiple_cota_2 = metodo_newton_raphson_para_raices_multiples(f, f_derivada_primera, f_derivada_segunda, semilla_p0, tolerancia=COTA_DE_ERROR_2)

extraer_ultimo_pn(lista_resultados_NR_multiple_cota_2)

"""Dado que el error entre dos iteraciones result√≥ $|p_n - p_{n-1}| = 0$, no hubo diferencia entre el valor de las aproximaciones consecutivas de la ra√≠z.
Esto se puede explicar debido a la cantidad de digitos significativos con la que trabaja la computadora, por lo cual concluimos que:

Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-12}$ es: 

$x = [1147.596288534586 \pm 10^{-12}]kg$

#### **1.2.2.5 M√©todo de la Secante:**

##### *Definiciones previas*

$f(x) = 0,001\frac{$}{kg^3}¬∑x¬∑(x‚àí1000kg)^2 - \$25000$

Dado que el m√©todo de la Secante proviene del m√©todo de Newton-Raphson, con el objetivo de no utilizar $f'(x)$, realizando la siguiente aproximaci√≥n:

$f'(p_{n-1}) ‚âÖ \frac{f(p_{n-2}) - f(p_{n-1})}{p_{n-2} - p_{n-1}}$ 

Es por esto que el m√©todo de la Secante posee las mismas condiciones de convergencia que el m√©todo de Newton-Raphson.

Gracias al an√°lisis realizado en el m√©todo de Newton-Raphson en donde:

Dado que $f$ es un polinomio de grado 3 $‚áí$ $f \in C^2[1100,1200]$

$ f(x) = 0$ $‚àÄ$ $x \in [1100, 1200]$, 

$f'(x) \neq 0$ $‚àÄ$ $x \in [1100, 1200]$

Entonces podemos concluir que el m√©todo de la Secante converger√° a la unica raiz contenida en el intervalo $[1100, 1200]$.

##### *Aplicaci√≥n del m√©todo* 

La semilla $p_0$ se obtiene a partir de la primer iteracion del m√©todo de la biseccion, en donde anteriormente se demostr√≥ que dicho m√©todo converger√° a la raiz.

Tomando el intervalo $[1100, 1200]$ ‚áí $p_0 = \frac{(a + b)}{2} = \frac{(1100 \cdot kg + 1200 \cdot kg)}{2} = 1150 kg$

La semilla $p_1$ tambi√©n la voy a obtener a partir del m√©todo de la bisecci√≥n, pero con la segunda iteraci√≥n.

Para esto verifico cual es mi nuevo intervalo:

$f(1150) = 0 ‚áí x = 1150kg$ es la ra√≠z de $f$.  

$f(1100) \cdot f(1150) < 0 ‚áí$ el nuevo intervalo es $[1100, 1150]$

$f(1150) \cdot f(1200) < 0 ‚áí$ el nuevo intervalo es $[1150, 1200]$
"""

f(1100)*f(1150) < 0

f(1150)*f(1200) < 0

"""Observando los resultados obtenidos, el nuevo intervalo resultante ser√° $[1100, 1150]$.

Por lo tanto la segunda semilla del m√©todo de la Secante ser√° la siguiente:

$p_1 = \frac{(a + b)}{2} = \frac{(1100 \cdot kg + 1150 \cdot kg)}{2} = 1125 kg$
"""

semilla_p0 = 1150
semilla_p1 = 1125

lista_resultados_secante_cota_1, encontrado_secante_cota_1 = metodo_secante(f, semilla_p0, semilla_p1, tolerancia=COTA_DE_ERROR_1)

extraer_ultimo_pn(lista_resultados_secante_cota_1)

"""Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-5}$ es: 

$x = [1147.59629 \pm 0.00001]kg$

"""

lista_resultados_secante_cota_2, encontrado_secante_cota_2 = metodo_secante(f, semilla_p0, semilla_p1, tolerancia=COTA_DE_ERROR_2)

extraer_ultimo_pn(lista_resultados_secante_cota_2)

"""Dado que el error entre dos iteraciones result√≥ $|p_n - p_{n-1}| = 0$, no hubo diferencia entre el valor de las aproximaciones consecutivas de la ra√≠z.
Esto se puede explicar debido a la cantidad de digitos significativos con la que trabaja la computadora, por lo cual concluimos que:

Dado que el m√©todo no imprimi√≥ ningun error y adem√°s el valor est√° dentro del intervalo $[1100; 1200]$, junto con lo anteriormente expuesto concluimos que la cantidad de producto m√≠nima para cumplir con la restricci√≥n de contribuci√≥n m√≠nima mensual y la justificaci√≥n del setup de las m√°quinas con la tolerancia de $1\cdot10^{-12}$ es: 

$x = [1147.596288534586 \pm 10^{-12}]kg$

### 1.2.3 (Pregunta $c$) Realizar una tabla con los resultados de las iteraciones, convergencia $P$ y la constante asint√≥tica $\lambda$. 
### En caso de que se encuentren m√°s de 12 iteraciones, solamente incluir en la tabla las primeras 5 iteraciones y luego las √∫ltimas 5.

En las siguientes tablas se muestran los valores correspondientes a todos los resultados obtenidos por cada m√©todo hasta encontrar la ra√≠z con la precisi√≥n pedida, o en su defecto hasta que el m√©todo se detenga por alguna de las siguientes causas:
- M√°xima cantidad de iteraciones (Decidida en 30 en base a los resultados generales).
- Valor m√°ximo de error entre iteraciones (en el caso en el que un m√©todo diverge).
- Valor m√≠nimo de error entre iteraciones (en el caso en el que el error actual no sea aritmeticamente operable por ser muy peque√±o).

Siendo que la computadora trabaja con una cantidad finita de d√≠gitos y la cota del error dada ($1\cdot10^{-13}$) la supera, ocurre que dos aproximaciones consecutivas de la ra√≠z poseen el mismo valor, lo cual no implica que se haya encontrado la ra√≠z exacta sino que es una limitaci√≥n de representaci√≥n.

Esto conlleva a que la constante asint√≥tica y el orden de convergencia no puedan ser calculados para aproximaciones de ra√≠z con mismo valor como sucede en la √∫ltima iteraci√≥n.

Esto sucede en la aplicaci√≥n de los m√©todos: 
- NR.
- NR modificado.
- Secante.

#### 1.2.3.1 M√©todo de Bisecci√≥n
"""

lista_pn_biseccion_cota_1 = extraer_pn_biseccion(lista_resultados_biseccion_cota_1)
lista_errores_biseccion_cota_1 = extraer_errores_biseccion(lista_resultados_biseccion_cota_1)
lista_alfa_biseccion_cota_1 = calcular_orden_de_convergencia_alfa(lista_pn_biseccion_cota_1)
lista_cte_asintotica_biseccion_cota_1 = calcular_cte_asintotica_lambda(lista_errores_biseccion_cota_1, lista_alfa_biseccion_cota_1)

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_biseccion_cota_1,lista_alfa_biseccion_cota_1,lista_cte_asintotica_biseccion_cota_1,['an', 'bn', 'pn', 'error','alfa','lambda'])
tabla_de_resultados

lista_pn_biseccion_cota_2 = extraer_pn_biseccion(lista_resultados_biseccion_cota_2)
lista_errores_biseccion_cota_2 = extraer_errores_biseccion(lista_resultados_biseccion_cota_2)
lista_alfa_biseccion_cota_2 = calcular_orden_de_convergencia_alfa(lista_pn_biseccion_cota_2)
lista_cte_asintotica_biseccion_cota_2 = calcular_cte_asintotica_lambda(lista_errores_biseccion_cota_2, lista_alfa_biseccion_cota_2)

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_biseccion_cota_2,lista_alfa_biseccion_cota_2,lista_cte_asintotica_biseccion_cota_2,['an', 'bn', 'pn', 'error','alfa','lambda'])
tabla_de_resultados

"""####  1.2.3.2 M√©todo de Punto Fijo"""

lista_pn_punto_fijo_cota_1 = extraer_pn(lista_resultados_punto_fijo_cota_1)
lista_alfa_punto_fijo_cota_1  = calcular_orden_de_convergencia_alfa(lista_pn_punto_fijo_cota_1)
lista_errores_punto_fijo_cota_1  = extraer_errores(lista_resultados_punto_fijo_cota_1)
lista_cte_asintotica_punto_fijo_cota_1  = calcular_cte_asintotica_lambda(lista_errores_punto_fijo_cota_1, lista_alfa_punto_fijo_cota_1 )

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_punto_fijo_cota_1,lista_alfa_punto_fijo_cota_1,lista_cte_asintotica_punto_fijo_cota_1,columnas=['pn', 'error','alfa','lambda'])
tabla_de_resultados

lista_pn_punto_fijo_cota_2 = extraer_pn(lista_resultados_punto_fijo_cota_2)
lista_alfa_punto_fijo_cota_2  = calcular_orden_de_convergencia_alfa(lista_pn_punto_fijo_cota_2)
lista_errores_punto_fijo_cota_2  = extraer_errores(lista_resultados_punto_fijo_cota_2)
lista_cte_asintotica_punto_fijo_cota_2  = calcular_cte_asintotica_lambda(lista_errores_punto_fijo_cota_2, lista_alfa_punto_fijo_cota_2 )

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_punto_fijo_cota_2,lista_alfa_punto_fijo_cota_2,lista_cte_asintotica_punto_fijo_cota_2,columnas=['pn', 'error','alfa','lambda'])
tabla_de_resultados

"""####  1.2.3.3 M√©todo de Newton-Raphson"""

lista_pn_NR_cota_1 = extraer_pn(lista_resultados_NR_cota_1)
lista_alfa_NR_cota_1 = calcular_orden_de_convergencia_alfa(lista_pn_NR_cota_1)
lista_errores_NR_cota_1 = extraer_errores(lista_resultados_NR_cota_1)
lista_cte_asintotica_NR_cota_1 = calcular_cte_asintotica_lambda(lista_errores_NR_cota_1, lista_alfa_NR_cota_1)

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_NR_cota_1,lista_alfa_NR_cota_1,lista_cte_asintotica_NR_cota_1,['pn', 'error','alfa','lambda'])
tabla_de_resultados

lista_pn_NR_cota_2 = extraer_pn(lista_resultados_NR_cota_2)
lista_alfa_NR_cota_2 = calcular_orden_de_convergencia_alfa(lista_pn_NR_cota_2)
lista_errores_NR_cota_2 = extraer_errores(lista_resultados_NR_cota_2)
lista_cte_asintotica_NR_cota_2 = calcular_cte_asintotica_lambda(lista_errores_NR_cota_2, lista_alfa_NR_cota_2)

tabla_de_resultados = lista_resultados_a_dataframe(lista_resultados_NR_cota_2,lista_alfa_NR_cota_2,lista_cte_asintotica_NR_cota_2,['pn', 'error','alfa','lambda'])
tabla_de_resultados

"""####  1.2.3.4 M√©todo de Newton-Raphson Modificado"""

lista_pn_NR_multiple_cota_1 = extraer_pn(lista_resultados_NR_multiple_cota_1)
lista_alfa_NR_multiple_cota_1 = calcular_orden_de_convergencia_alfa(lista_pn_NR_multiple_cota_1)
lista_errores_NR_multiple_cota_1 = extraer_errores(lista_resultados_NR_multiple_cota_1)
lista_cte_asintotica_NR_multiple_cota_1 = calcular_cte_asintotica_lambda(lista_errores_NR_multiple_cota_1, lista_alfa_NR_multiple_cota_1)

lista_resultados_a_dataframe(lista_resultados_NR_multiple_cota_1,lista_alfa_NR_multiple_cota_1,lista_cte_asintotica_NR_multiple_cota_1,['pn', 'error','alfa','lambda'])

lista_pn_NR_multiple_cota_2 = extraer_pn(lista_resultados_NR_multiple_cota_2)
lista_alfa_NR_multiple_cota_2 = calcular_orden_de_convergencia_alfa(lista_pn_NR_multiple_cota_2)
lista_errores_NR_multiple_cota_2 = extraer_errores(lista_resultados_NR_multiple_cota_2)
lista_cte_asintotica_NR_multiple_cota_2 = calcular_cte_asintotica_lambda(lista_errores_NR_multiple_cota_2, lista_alfa_NR_multiple_cota_2)

lista_resultados_a_dataframe(lista_resultados_NR_multiple_cota_2,lista_alfa_NR_multiple_cota_2,lista_cte_asintotica_NR_multiple_cota_2,['pn', 'error','alfa','lambda'])

"""#### 1.2.3.5 M√©todo de la Secante"""

lista_pn_secante_cota_1 = extraer_pn(lista_resultados_secante_cota_1)
lista_alfa_secante_cota_1 = calcular_orden_de_convergencia_alfa(lista_pn_secante_cota_1)
lista_errores_secante_cota_1 = extraer_errores(lista_resultados_secante_cota_1)
lista_cte_asintotica_secante_cota_1 = calcular_cte_asintotica_lambda(lista_errores_secante_cota_1, lista_alfa_secante_cota_1)

lista_resultados_a_dataframe(lista_resultados_secante_cota_1,lista_alfa_secante_cota_1,lista_cte_asintotica_secante_cota_1,['pn', 'error','alfa','lambda'])

lista_pn_secante_cota_2 = extraer_pn(lista_resultados_secante_cota_2)
lista_alfa_secante_cota_2 = calcular_orden_de_convergencia_alfa(lista_pn_secante_cota_2)
lista_errores_secante_cota_2 = extraer_errores(lista_resultados_secante_cota_2)
lista_cte_asintotica_secante_cota_2 = calcular_cte_asintotica_lambda(lista_errores_secante_cota_2, lista_alfa_secante_cota_2)

lista_resultados_a_dataframe(lista_resultados_secante_cota_2,lista_alfa_secante_cota_2,lista_cte_asintotica_secante_cota_2,['pn', 'error','alfa','lambda'])

"""### 1.2.4 (Pregunta $d$) Compare los resultados obtenidos para los distintos m√©todos y cotas, grafique el orden de convergencia $P$ y la constante asint√≥tica $\lambda$ para todos los casos. Realice un gr√°fico $log_{10}(\Delta x)$ vs iteraciones, para visualizar el comportamiento de la constante asint√≥tica y el orden de convergencia. Discuta ventajas y desventajas. ¬øSon las que esperaba en base a la teor√≠a?

#### 1.2.4.1 Funciones auxiliares para plots:
"""

def plotear_puntos_vs_iter_log(lista_valores_en_y,color, label):
    label_ploteado = False
    for x in range(len(lista_valores_en_y)):
        if lista_valores_en_y[x] != None:
            if label_ploteado:
                plt.plot(x,np.log10(lista_valores_en_y[x]), marker="o", markersize=5, color=color)
            else:
                plt.plot(x,np.log10(lista_valores_en_y[x]), marker="o", markersize=5, color=color, label = label)
                label_ploteado = True


    

def plotear_puntos_vs_iter(lista_valores_en_y,color, label):
    label_ploteado = False
    for x in range(len(lista_valores_en_y)):
        if lista_valores_en_y[x] != None:
            if label_ploteado:
                plt.plot(x,lista_valores_en_y[x], marker="o", markersize=5, color=color)
            else:
                plt.plot(x,lista_valores_en_y[x], marker="o", markersize=5, color=color, label = label)
                label_ploteado = True

"""####  1.2.4.2 Graficos orden de convergencia $Œ±$ vs Iteraciones

##### Con cota de error 1:
"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica orden de convergencia alpha vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("Œ±")

plotear_puntos_vs_iter(lista_alfa_biseccion_cota_1,'red', "biseccion")
plotear_puntos_vs_iter(lista_alfa_punto_fijo_cota_1,'green', "punto fijo")
plotear_puntos_vs_iter(lista_alfa_NR_cota_1,'blue', "NR")
plotear_puntos_vs_iter(lista_alfa_NR_multiple_cota_1,'orange', "NR modif")
plotear_puntos_vs_iter(lista_alfa_secante_cota_1,'purple',"secante" )

ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(1))
ax.set_xlim(0, 30)
ax.set_ylim(0, 41)

ax.grid()
plt.legend()
plt.show()

"""Para ver con mayor precisi√≥n los valores exceptuando el primer valor del m√©todo de la secante (debido a su lejan√≠a respecto de los dem√°s valores en el gr√°fico anterior):"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica orden de convergencia alpha vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("Œ±")

plotear_puntos_vs_iter(lista_alfa_biseccion_cota_1,'red', "biseccion")
plotear_puntos_vs_iter(lista_alfa_punto_fijo_cota_1,'green', "punto fijo")
plotear_puntos_vs_iter(lista_alfa_NR_cota_1,'blue', "NR")
plotear_puntos_vs_iter(lista_alfa_NR_multiple_cota_1,'orange', "NR modif")
plotear_puntos_vs_iter(lista_alfa_secante_cota_1,'purple',"secante" )


ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(0.2))
ax.set_xlim(0, 30)
ax.set_ylim(0, 5)

ax.grid()
plt.legend()
plt.show()

"""##### Con cota de error 2:"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica orden de convergencia alpha vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("Œ±")

plotear_puntos_vs_iter(lista_alfa_biseccion_cota_2,'red', "biseccion")
plotear_puntos_vs_iter(lista_alfa_punto_fijo_cota_2,'green', "punto fijo")
plotear_puntos_vs_iter(lista_alfa_NR_cota_2,'blue', "NR")
plotear_puntos_vs_iter(lista_alfa_NR_multiple_cota_2,'orange', "NR modif")
plotear_puntos_vs_iter(lista_alfa_secante_cota_2,'purple', "secante")

ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(1))
ax.set_xlim(0, 30)
ax.set_ylim(0, 41)


ax.grid()
plt.legend()
plt.show()

"""Para ver con mayor precisi√≥n los valores exceptuando el primer valor del m√©todo de la secante (debido a su lejan√≠a respecto de los dem√°s valores en el gr√°fico anterior):"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica orden de convergencia alpha vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("Œ±")

plotear_puntos_vs_iter(lista_alfa_biseccion_cota_1,'red', "biseccion")
plotear_puntos_vs_iter(lista_alfa_punto_fijo_cota_1,'green', "punto fijo")
plotear_puntos_vs_iter(lista_alfa_NR_cota_1,'blue', "NR")
plotear_puntos_vs_iter(lista_alfa_NR_multiple_cota_1,'orange', "NR modif")
plotear_puntos_vs_iter(lista_alfa_secante_cota_1,'purple',"secante" )


ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(0.2))
ax.set_xlim(0, 30)
ax.set_ylim(0, 5)

ax.grid()
plt.legend()
plt.show()

"""##### Conclusiones:
- En cuanto a orden de convergencia podemos ver que la bisecci√≥n siempre permanece con valor constante por como se van realizando las divisiones de subintervalos en cada iteraci√≥n, y queda claro que efectivamente tiene convergencia lineal.
- En cuanto al orden de convergencia de la secante, vemos que la estimaci√≥n del valor del orden de convergencia va oscilando y tiende a converger aproximadamente en 1.5, lo cual confirma que para este caso se tiene una convergencia supralineal.
- En cuanto al orden de convergencia de Newton-Raphson y NR modificado vemos que, como hab√≠amos visto en el an√°lisis gr√°fico, la ra√≠z era simple y por lo tanto ambos m√©todos coinciden en su orden de convergencia cuadr√°tico, lo cual se ve rapidamente en el c√°lculo de $\alpha$ para los dos.
- En cuanto al orden de convergencia del punto fijo, los valores resultantes directamente no tienen sentido ya que el m√©todo en s√≠ diverge para cualquier semilla que se elija en el intervalo mencionado antes.

####  1.2.4.3 Graficos constante asint√≥tica $\lambda$ vs Iteraciones

##### Con cota de error 1:
"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica constante asint√≥tica $\lambda$ vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("$\lambda$")

plotear_puntos_vs_iter(lista_cte_asintotica_biseccion_cota_1,'red', "biseccion")
plotear_puntos_vs_iter(lista_cte_asintotica_punto_fijo_cota_1,'green', "punto fijo")
plotear_puntos_vs_iter(lista_cte_asintotica_NR_cota_1,'blue', "NR")
plotear_puntos_vs_iter(lista_cte_asintotica_NR_multiple_cota_1,'orange', "NR modif")
plotear_puntos_vs_iter(lista_cte_asintotica_secante_cota_1,'purple', "secante")


ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(0.1))
ax.set_xlim(0, 30)
ax.set_ylim(-0.2, 1.3)


ax.grid()
plt.legend()

plt.show()

"""##### Con cota de error 2:"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica constante asint√≥tica $\lambda$ vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("$\lambda$")

plotear_puntos_vs_iter(lista_cte_asintotica_biseccion_cota_2,'red', "biseccion")
plotear_puntos_vs_iter(lista_cte_asintotica_punto_fijo_cota_2,'green', "punto fijo")
plotear_puntos_vs_iter(lista_cte_asintotica_NR_cota_2,'blue', "NR")
plotear_puntos_vs_iter(lista_cte_asintotica_NR_multiple_cota_2,'orange', "NR modif")
plotear_puntos_vs_iter(lista_cte_asintotica_secante_cota_2,'purple', "secante")

ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(0.1))
ax.set_xlim(0, 30)
ax.set_ylim(-0.2, 1.3)

ax.grid()
plt.legend()

plt.show()

"""##### Conclusiones:
- Se observa que para el punto fijo los valores de $Œª$ son practicamente cero, pero hay que tener en claro que esos valores no tienen sentido ya que si se hubiera podido calcular una iteraci√≥n m√°s (si se hubiese podido representar), su valor ser√≠a mucho mayor a 1 de donde se nota la divergencia.
- El m√©todo de la bisecci√≥n tiene $Œª$ constante $0.5$ y tiene sentido ya que siempre el error va disminuyendo en la misma raz√≥n ya que siempre se subdividen los intervalos a la mitad.
- En los m√©todos de NR el $Œª$ es muy cercano a cero, pero en estos casos si tiene sentido ya que se llega a la precisi√≥n deseada muy rapidamente.
- Para el m√©todo de la secante $Œª$ no toma valores tan cercanos a cero al principio (como los de NR, por lo tanto tiene que reaizar m√°s iteraciones), pero a√∫n as√≠ los mismos terminan siendo cercanos a cero en pocas.

####  1.2.4.4 Graficos  $log_{10}(\Delta x)$ vs Iteraciones

##### Con cota de error 1:
"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica  $Log(\Delta x)$ vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("$Log(\Delta x)$")

plotear_puntos_vs_iter_log(lista_errores_biseccion_cota_1,"red" ,"biseccion")
plotear_puntos_vs_iter_log(lista_errores_punto_fijo_cota_1,"green" ,"punto fijo")
plotear_puntos_vs_iter_log(lista_errores_NR_cota_1,"blue" ,"NR")
plotear_puntos_vs_iter_log(lista_errores_NR_multiple_cota_1,"orange" ,"NR modif")
plotear_puntos_vs_iter_log(lista_errores_secante_cota_1,"purple" ,"secante")

ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(2))
ax.set_xlim(-1, 30)
ax.set_ylim(-10, 35)

ax.grid()
plt.legend()

plt.show()

"""##### Con cota de error 2:"""

fig, ax = plt.subplots(figsize=(20, 10))

plt.title("Grafica  $Log(\Delta x)$ vs Iteraciones")
plt.xlabel("Iteraciones")
plt.ylabel("$Log(\Delta x)$")

plotear_puntos_vs_iter_log(lista_errores_biseccion_cota_2,"red","biseccion")
plotear_puntos_vs_iter_log(lista_errores_punto_fijo_cota_2,"green","punto fijo")
plotear_puntos_vs_iter_log(lista_errores_NR_cota_2,"blue","NR")
plotear_puntos_vs_iter_log(lista_errores_NR_multiple_cota_2,"orange","NR modif")
plotear_puntos_vs_iter_log(lista_errores_secante_cota_2,"purple" ,"secante")



ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(2))
ax.set_xlim(-1, 30)
ax.set_ylim(-10, 35)

ax.grid()
plt.legend()

plt.show()

"""##### Conclusiones:
- Se puede observar a partir de los gr√°ficos que el m√©todo de la bisecci√≥n es el m√°s lento en llegar a la cota de error dada por la tolerancia.
- Luego, se observa que los m√©todos de NR y NR modificado fueron los m√°s eficientes, ya que con muy pocas iteraciones llegaron a ambas cotas de error dadas por las tolerancias.  
- Ac√° tambien se puede ver c√≥mo diverge el m√©todo de punto fijo en pocas iteraciones.
- A su vez el m√©todo de la secante presenta resultados esperados ya que llega a las cotas de error dadas por las tolerancias en una cantidad de iteraciones menor a la de la bisecci√≥n, pero mayor a las de los m√©todos de NR, dado su comportamiento supralineal.

___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# ***2. Splines para aproximacion de curvas***

## ***2.1 Implementaci√≥n del m√©todo de iterpolacion de Spline c√∫bica:***

Dada una funci√≥n $f$ definida en [a,b] y un conjunto de nodos: $x_0 < x_1 < ... < x_n$.

Se define trazadror c√∫bico o Spline C√∫bica a la funcion $S(x)$ que satisface las condiciones siguientes:

1. $S(x)$ es un polinomio c√∫bico, denotado $S_i(x)$, en el subintervalo $[x_i,x_{i+1}]$ para cada $i=0,1,...,n-1$.
2. $S(x_i) = f(x_i)$  $\forall$  $i=0,1,...,n$.
3. $S_{i+1}(x_{i+1})=S_i(x_{i+1})$  $\forall$  $i=0,1,...,n-2$.
4. $S'_{i+1}(x_{i+1})=S'_i(x_{i+1})$  $\forall$  $i=0,1,...,n-2$
5. $S''_{i+1}(x_{i+1})=S''_i(x_{i+1})$  $\forall$  $i=0,1,...,n-2$
6. Una de las siguientes condiciones de frontera se satisface:
   1. $S''(x_0)=S''(x_n)$ frontera libre o natural.
   2. $S'(x_0)=f'(x_0)$ y $S'(x_n)=f'(x_n)$  frontera ligada o condicionada.

En la consigna se pide trabajar con la frontera ligada por lo tanto utilizaremos la √∫ltima condici√≥n para el ejercicio.

### **2.1.1 Definiciones de funciones de c√°lculo de coeficientes:**

*(Notaci√≥n: Denominamos **subsplines** a las particiones de las Splines seg√∫n su definici√≥n en los subintervalos)*

Para construir una spline definida en un intervalo que se dividi√≥ en $n$ subintervalos requiere determinar $4n$ constantes. Para construir el spline c√∫bico para una funci√≥n dada f, las condiciones en la definici√≥n se aplican a los polinomios c√∫bicos.

$S_i(x) = a_i + b_i (x ‚àí x_i) + c_i (x ‚àí x_i )^2 + d_i (x ‚àí x_i )^3$,

para cada $i = 0,1,...,n-1$. Puesto que $S_i(x_i) = a_i = f(x_i)$, la condici√≥n **3.** se puede aplicar para obtener

$a_{i+1} = S_{i+1}(x _{i+1}) = S_i (x _{i+1}) = a_i + b_i(x_{i+1} ‚àí x_i ) + c_i(x_{i+1} ‚àí x _i )^2 + d_i (x _{i+1} ‚àí x _i )^3$,

para cada $i= 0,1,...,n-2$.

Como los t√©rminos $x_{i+1} - x_i$ son usados muchas veces, por lo tanto es conveniente una notaci√≥n mas simple

$h_i = x_{i+1} - x_i$

para cada  $i = 0,1,...,n-1$

Para esta notaci√≥n, creamos la siguiente funci√≥n que devuelve una lista de todos los elementos $h_i$

h_lista $= [h_1,h_2,...,h_{n-1}]$
"""

def crear_lista_de_incrementos_hi(tabla_de_datos_sobre_nodos: list):
    h_lista = []
    # voy de i = 0 a n-1
    for i in range(len(tabla_de_datos_sobre_nodos)-1):
        h_i = tabla_de_datos_sobre_nodos[i+1][0] - tabla_de_datos_sobre_nodos[i][0]
        h_lista.append(h_i)
    return h_lista

"""Tambi√©n definimos $a_n = f(x_n)$, entonces tenemos:

$a_{i+1} = a_i = b_i h_i +c_i h_i¬≤ + d_i h_i¬≥$

para cada $i = 0,1,...,n-1$

Para organizar los datos, utilizamos la siguiente funcion donde a partir de los datos que tenemos, simplemente guardamos los puntos donde sabemos los valores de $f(x_n)$ en una lista *a_lista*
"""

def crear_lista_de_coeficientes_independientes_ai(tabla_de_datos_sobre_nodos: list):
    a_lista = []
    for i in range(len(tabla_de_datos_sobre_nodos)):
        a_i = tabla_de_datos_sobre_nodos[i][1] 
        a_lista.append(a_i)
    return a_lista

"""
Apartir de:

$S_i'(x) = b_i + 2c_i (x ‚àí x_i ) + 3d_i (x ‚àí x_i )^2$;

$S_i'(x_i) = b_i$  $\forall$  $ i = 0, 1,..., n-1 $

y las condiciones 4. y 5. Se puede desarrollar para llegar a expresar los coeficientes lineales de la forma:

$b_i = \frac{1}{h_i} (a_{i+1} - a_i) - \frac{h_i}{3} (2c_i +  c_{i+1})$"""

def crear_lista_de_coeficientes_lineales_bi(h_lista: list, a_lista: list, c_lista: list):
    nro_sub_splines = len(h_lista)
    lista_bi = []

    for i in range(nro_sub_splines):
        b_i = ((1/h_lista[i]) * (a_lista[i+1] - a_lista[i])) - ((h_lista[i]/3) * (2 * c_lista[i] + c_lista[i+1]))
        lista_bi.append(b_i)

    return lista_bi

"""De aqu√≠, reduciendo en uno el indice y reemplazando los $b_i$ se llega a:

$h_{i-1}c_{i-1} + 2(h_{i-1} + h_i)c_i + h_i c_{i+1} =  \frac{3}{h_i} (a_{i+1} - a_i) - \frac{3}{h_{i-1}} (a_i - a_{i-1})$

Este sistema contiene solo los $\{c_i\}_{i=0}^n$ como inc√≥gnitas, ya que los valores de $\{h_i\}_{i=0}^n$ y de $\{a_i\}_{i=0}^n$ son conocidos, los $h$ son el espaciado entre los nodos y los $a$ son los valores de la funci√≥n en los nodos.

**Teorema**: Si $f$ se define en $a= x_0 < x_1 < ... < x_b = b$ y es diferenciable en $a$ y $b$, entonces $f$ tiene un √∫nico spline interpolante $S$ condicionado en los nodos $x_0, x_1,..., x_n$; es decir, un spline interpolante que satisface las condiciones de frontera condicionada $S'(a) = f'(a) y $S'(b) = f'(b)$

**Demostraci√≥n**: Para verificar que la ecuaci√≥n anterior se cumple, utilizamos que como: $f'(a) = S'(a) = S'(x_0) = b_0$, y desarrollando la ecuacion vista antes $b_i = \frac{1}{h_i} (a_{i+1} - a_i) - \frac{h_i}{3} (2c_i +  c_{i+1})$ con $i = 0$ llegamos a:

$2h_0c_0 + h_0c_1 = \frac{3}{h_0}(a_1-a_0)-3f'(a)$

y con $i=n-1$:

$h_{n-1}c_{n-1} + 2h_{n-1}c_n = 3f'(b) - \frac{3}{h_{n-1}}(a_n-a_{n-1})$

con todos estos datos se puede determinar el sistema lineal $Ax = b$

$ 
A = 
\begin{pmatrix}
2h_0 & h_0 & 0 & ... & ... & 0 \\
h_0 & 2(h_0 + h_1) & h_1 & ... & ... & ...\\
0 & h_1 & 2(h_1 + h_2) & h_2 & ... & ... \\
... & ... & ... & ... & ... & 0 \\
... & ... & ... & h_{n-2} & 2(h_{n-2} + h_{n-1}) & h_{n-1} \\
0 & ... & ... & 0 & h_{n-1} & 2h_{n-1} \\
\end{pmatrix} 
;
$



$
b = 
\begin{pmatrix}
\frac{3}{h_0} (a_1 - a_0) - 3f'(x_0) \\
\frac{3}{h_1} (a_2 - a_1) - \frac{3}{h_0} (a_1 - a_0) \\
... \\ 
\frac{3}{h_{n-1}} (a_n - a_{n-1}) - \frac{3}{h_{n-2}} (a_{n-1} - a_{n-2}) \\
3f'(x_n) - \frac{3}{h_{n-1}} (a_n - a_{n-1})
\end{pmatrix}
;
$
"""

def matriz_A(h_lista: list):
    nro_sub_splines = len(h_lista)

    matriz_A = [([0]*(nro_sub_splines+1)) for _ in range(nro_sub_splines+1)]

    for i in range(nro_sub_splines+1):
        for j in range(nro_sub_splines+1):
            if i == j:
                if i == 0:
                    matriz_A[i][j] = 2 * h_lista[i]
                    matriz_A[i][j+1] = h_lista[i]
                elif i == nro_sub_splines:
                    matriz_A[i][j] = 2 * h_lista[i-1]
                    matriz_A[i][j-1] = h_lista[i-1]
                else:
                    matriz_A[i][j-1] = h_lista[i-1]
                    matriz_A[i][j] = 2 * (h_lista[i-1] + h_lista[i])
                    matriz_A[i][j+1] = h_lista[i]

    return matriz_A

def matriz_b(h_lista: list, a_lista: list, derivada_f_x0, derivada_f_xn):
    nro_sub_splines = len(h_lista)
    b = []

    for i in range(nro_sub_splines+1):
        if i == 0:
            b.append((3/h_lista[i] * (a_lista[i+1] - a_lista[i])) - (3 * derivada_f_x0))
        elif i == nro_sub_splines:
            b.append((3 * derivada_f_xn) - (3/h_lista[i-1] * (a_lista[i] - a_lista[i-1])))
        else:
            b.append(((3/h_lista[i]) * (a_lista[i+1] - a_lista[i])) - ((3/h_lista[i-1]) * (a_lista[i] - a_lista[i-1])))
    
    return b

"""y nuestra incognita $x = \begin{pmatrix} c_0 \\ c_1 \\ ... \\ c_n \end{pmatrix}$ que simplemente la obtenemos haciendo `lista_ci = np.linalg.solve(A, b)`

Ademas, teniendo en cuenta que $S''(x_n) = 2c_n$  y la condicion 5. se puede llegar a expresar los coeficientes c√∫bicos de la forma:

$d_i = \frac{1}{3h_i} (c_{i+1} - c_i)$
"""

def crear_lista_de_coeficientes_cubicos_di(h_lista: list, c_lista: list):
    nro_sub_splines = len(h_lista)
    lista_di =[]

    for i in range(nro_sub_splines):
        d_i = (1/(3*h_lista[i]))*(c_lista[i+1]-c_lista[i])
        lista_di.append(d_i)
    return lista_di

"""### **2.1.2 Definiciones de funciones auxiliares para ploteo:**

Funcion auxiliar para ploteo de subsplines:
"""

def generar_muestras_de_subspline_i(x,lista_ai: list, lista_bi: list, lista_ci: list, lista_di: list, i): 
    return (lista_ai[i] + lista_bi[i]*(x-x[0]) + lista_ci[i]*((x-x[0])**2)+lista_di[i]*((x-x[0])**3))

"""Funci√≥n auxiliar para armado de las tabla con coeficientes resultantes de la interpolaci√≥n:"""

def curva_dataframe(nombre,coeficientes_spline):
    lista_nombres = [[nombre,nombre,nombre,nombre],["a","b","c","d"]]
    tuplas = list(zip(*lista_nombres))
    indice = pd.MultiIndex.from_tuples(tuplas, names=["Spline", "Coeficiente"])
    tabla_de_datos = pd.DataFrame(coeficientes_spline, index=indice)
    return tabla_de_datos

"""### **2.1.3 Metodo de interpolaci√≥n de Spline c√∫bica**

Esta funci√≥n recibe la informaci√≥n acerca de los nodos a interpolar, y como se va a calcular interpolaci√≥n por spline ligada se necesita el valor de la derivada en los nodos m√°s extremos de la misma.
Devuelve una lista cuyos elementos son listas que contienen los coeficientes respectivos a cada subspline $i$
"""

def interpolacion_spline(nodos: list, derivada_f_x0, derivada_f_xn):
  lista_hi = crear_lista_de_incrementos_hi(nodos)
  lista_ai = crear_lista_de_coeficientes_independientes_ai(nodos)
  A = matriz_A(lista_hi)
  b = matriz_b(lista_hi, lista_ai, derivada_f_x0, derivada_f_xn)
  lista_ci = np.linalg.solve(A, b)
  lista_bi = crear_lista_de_coeficientes_lineales_bi(lista_hi, lista_ai, lista_ci)
  lista_di = crear_lista_de_coeficientes_cubicos_di(lista_hi, lista_ci)
  return [lista_ai, lista_bi, lista_ci, lista_di]

"""##### **Ejemplo** del Burden"""

#datos
tabla_de_datos_sobre_nodos = [(0,1), (1,np.e), (2,np.e**2), (3,np.e**3)] # Las tuplas significan esto -> (x, f(x))
# derivadas
derivada_f_x0 = 1
derivada_f_xn = np.e**3

lista_hi = crear_lista_de_incrementos_hi(tabla_de_datos_sobre_nodos)
lista_ai = crear_lista_de_coeficientes_independientes_ai(tabla_de_datos_sobre_nodos)

lista_hi

lista_ai

A = (matriz_A(lista_hi))
for i in range(len(A)):
    print(A[i])

b = (matriz_b(lista_hi, lista_ai, derivada_f_x0, derivada_f_xn))
b

lista_ci = np.linalg.solve(A, b)
print(lista_ci)

lista_bi = crear_lista_de_coeficientes_lineales_bi(lista_hi, lista_ai, lista_ci)
lista_bi

lista_di = crear_lista_de_coeficientes_cubicos_di(lista_hi, lista_ci)
lista_di

coeficientes_ejemplo = interpolacion_spline(tabla_de_datos_sobre_nodos,derivada_f_x0,derivada_f_xn)

interval_1 = np.linspace(0,1,400) # devuelve un arreglo de 400 valores entre 0 y 1
interval_2 = np.linspace(1,2,400) # devuelve un arreglo de 400 valores entre 1 y 2
interval_3 = np.linspace(2,3,400) # devuelve un arreglo de 400 valores entre 2 y 3

subspline_1 = generar_muestras_de_subspline_i(interval_1,coeficientes_ejemplo[0],coeficientes_ejemplo[1],coeficientes_ejemplo[2],coeficientes_ejemplo[3],0)
subspline_2 = generar_muestras_de_subspline_i(interval_2,coeficientes_ejemplo[0],coeficientes_ejemplo[1],coeficientes_ejemplo[2],coeficientes_ejemplo[3],1)
subspline_3 = generar_muestras_de_subspline_i(interval_3,coeficientes_ejemplo[0],coeficientes_ejemplo[1],coeficientes_ejemplo[2],coeficientes_ejemplo[3],2)

plt.rcParams["figure.figsize"] = [6,6]
plt.rcParams["figure.autolayout"] = True
plt.plot(interval_1,subspline_1,'b')
plt.plot(interval_2,subspline_2,'b')
plt.plot(interval_3,subspline_3,'b')
plt.grid()
plt.show()

"""## ***2.2 Planteo del problema***

### **2.2.1 Uso de datos, interpolaci√≥n y tabla de coeficientes resultantes**:

Cargamos en una lista la informaci√≥n necesaria para la interpolaci√≥n de la siguiente forma:
$(x ,f(x))$
"""

nodos_spline_1 = [(1,3),(2,3.7),(5,3.9),(6,4.2),(7,5.7),(8,6.6),(10,7.1),(13,6.7),(17,4.5)]
derivadas_spline_1 = (1,-(2/3))
nodos_spline_2 = [(17,4.5),(20,7),(23,6.1),(24,5.6),(25,5.8),(27,5.2),(27.7,4.1)]
derivadas_spline_2 = (3,-4)
nodos_spline_3 = [(27.7,4.1),(28,4.3),(29,4.1),(30,3)]
derivadas_spline_3 = (1/3,-(3/2))

"""Calculamos los coeficientes de cada spline:"""

coeficientes_spline_1 = interpolacion_spline(nodos_spline_1,derivadas_spline_1[0],derivadas_spline_1[1])
coeficientes_spline_2 = interpolacion_spline(nodos_spline_2,derivadas_spline_2[0],derivadas_spline_2[1])
coeficientes_spline_3 = interpolacion_spline(nodos_spline_3,derivadas_spline_3[0],derivadas_spline_3[1])

"""Se obtiene la tabla de valores con los coeficientes:"""

df1 = curva_dataframe("Spline 1",coeficientes_spline_1)
df2 = curva_dataframe("Spline 2",coeficientes_spline_2)
df3 = curva_dataframe("Spline 3",coeficientes_spline_3)
frames = [df1,df2,df3]
df_total = pd.concat(frames).T

df_total

"""### **2.2.2 Gr√°fico**

A continuaci√≥n se asigna cada intervalo a graficar seg√∫n cada curva y luego se calculan valores (muestras) de cada subspline para poder graficarlas:

#### Curva 1
"""

intervalo_1_curva_1 = np.linspace(1,2,100)
intervalo_2_curva_1 = np.linspace(2,5,100)
intervalo_3_curva_1 = np.linspace(5,6,100)
intervalo_4_curva_1 = np.linspace(6,7,100)
intervalo_5_curva_1 = np.linspace(7,8,100)
intervalo_6_curva_1 = np.linspace(8,10,100)
intervalo_7_curva_1 = np.linspace(10,13,100)
intervalo_8_curva_1 = np.linspace(13,17,100)

muestras_subspline_1_curva_1 = generar_muestras_de_subspline_i(intervalo_1_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],0)
muestras_subspline_2_curva_1 = generar_muestras_de_subspline_i(intervalo_2_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],1)
muestras_subspline_3_curva_1 = generar_muestras_de_subspline_i(intervalo_3_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],2)
muestras_subspline_4_curva_1 = generar_muestras_de_subspline_i(intervalo_4_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],3)
muestras_subspline_5_curva_1 = generar_muestras_de_subspline_i(intervalo_5_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],4)
muestras_subspline_6_curva_1 = generar_muestras_de_subspline_i(intervalo_6_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],5)
muestras_subspline_7_curva_1 = generar_muestras_de_subspline_i(intervalo_7_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],6)
muestras_subspline_8_curva_1 = generar_muestras_de_subspline_i(intervalo_8_curva_1,coeficientes_spline_1[0],coeficientes_spline_1[1],coeficientes_spline_1[2],coeficientes_spline_1[3],7)

"""#### Curva 2"""

intervalo_1_curva_2 = np.linspace(17,20,100)
intervalo_2_curva_2 = np.linspace(20,23,100)
intervalo_3_curva_2 = np.linspace(23,24,100)
intervalo_4_curva_2 = np.linspace(24,25,100)
intervalo_5_curva_2 = np.linspace(25,27,100)
intervalo_6_curva_2 = np.linspace(27,27.7,100)

muestras_subspline_1_curva_2 = generar_muestras_de_subspline_i(intervalo_1_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],0)
muestras_subspline_2_curva_2 = generar_muestras_de_subspline_i(intervalo_2_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],1)
muestras_subspline_3_curva_2 = generar_muestras_de_subspline_i(intervalo_3_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],2)
muestras_subspline_4_curva_2 = generar_muestras_de_subspline_i(intervalo_4_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],3)
muestras_subspline_5_curva_2 = generar_muestras_de_subspline_i(intervalo_5_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],4)
muestras_subspline_6_curva_2 = generar_muestras_de_subspline_i(intervalo_6_curva_2,coeficientes_spline_2[0],coeficientes_spline_2[1],coeficientes_spline_2[2],coeficientes_spline_2[3],5)

"""#### Curva 3"""

intervalo_1_curva_3 = np.linspace(27.7,28,100)
intervalo_2_curva_3 = np.linspace(28,29,100)
intervalo_3_curva_3 = np.linspace(29,30,100)

muestras_subspline_1_curva_3 = generar_muestras_de_subspline_i(intervalo_1_curva_3,coeficientes_spline_3[0],coeficientes_spline_3[1],coeficientes_spline_3[2],coeficientes_spline_3[3],0)
muestras_subspline_2_curva_3 = generar_muestras_de_subspline_i(intervalo_2_curva_3,coeficientes_spline_3[0],coeficientes_spline_3[1],coeficientes_spline_3[2],coeficientes_spline_3[3],1)
muestras_subspline_3_curva_3 = generar_muestras_de_subspline_i(intervalo_3_curva_3,coeficientes_spline_3[0],coeficientes_spline_3[1],coeficientes_spline_3[2],coeficientes_spline_3[3],2)

"""#### Ploteo"""

fig, ax = plt.subplots(figsize=(20, 6))


plt.rcParams["figure.autolayout"] = True

plt.title("Splines halladas con los datos de la tabla",fontsize=20)
plt.xlabel("$x$",fontsize=15)
plt.ylabel("$f(x)$", fontsize=15)


# grafico spline 1
plt.plot(intervalo_1_curva_1,muestras_subspline_1_curva_1,'r', label="Spline 1")
plt.plot(intervalo_2_curva_1,muestras_subspline_2_curva_1,'r')
plt.plot(intervalo_3_curva_1,muestras_subspline_3_curva_1,'r')
plt.plot(intervalo_4_curva_1,muestras_subspline_4_curva_1,'r')
plt.plot(intervalo_5_curva_1,muestras_subspline_5_curva_1,'r')
plt.plot(intervalo_6_curva_1,muestras_subspline_6_curva_1,'r')
plt.plot(intervalo_7_curva_1,muestras_subspline_7_curva_1,'r')
plt.plot(intervalo_8_curva_1,muestras_subspline_8_curva_1,'r')
# grafico spline 2
plt.plot(intervalo_1_curva_2,muestras_subspline_1_curva_2,'g', label="Spline 2")
plt.plot(intervalo_2_curva_2,muestras_subspline_2_curva_2,'g')
plt.plot(intervalo_3_curva_2,muestras_subspline_3_curva_2,'g')
plt.plot(intervalo_4_curva_2,muestras_subspline_4_curva_2,'g')
plt.plot(intervalo_5_curva_2,muestras_subspline_5_curva_2,'g')
plt.plot(intervalo_6_curva_2,muestras_subspline_6_curva_2,'g')
# grafico spline 3
plt.plot(intervalo_1_curva_3,muestras_subspline_1_curva_3,'b', label="Spline 3")
plt.plot(intervalo_2_curva_3,muestras_subspline_2_curva_3,'b')
plt.plot(intervalo_3_curva_3,muestras_subspline_3_curva_3,'b')

# graficamos los puntos dados por el ejercicio

label_ploteado = False
for x,y in nodos_spline_1:
    if label_ploteado:
        plt.plot(x,y,'ro')
    else:
        plt.plot(x,y,'ro', label = "Nodos spline 1")
        label_ploteado = True

label_ploteado = False
for x,y in nodos_spline_2:
    if label_ploteado:
        plt.plot(x,y,'go')
    else:
        plt.plot(x,y,'go', label = "Nodos spline 2")
        label_ploteado = True

label_ploteado = False
for x,y in nodos_spline_3:
    if label_ploteado:
        plt.plot(x,y,'bo')
    else:
        plt.plot(x,y,'bo', label = "Nodos spline 1")
        label_ploteado = True



ax.xaxis.set_major_locator(MultipleLocator(1))
ax.yaxis.set_major_locator(MultipleLocator(1))
ax.set_xlim(0, 32)
ax.set_ylim(0, 8)

plt.legend()
ax.grid()
plt.show()

"""### **2.2.3 Conclusiones**:

Se puede observar que la aproximaci√≥n realizada en general resulta en una buena aproximaci√≥n de las funciones interpoladas, aunque hay que destacar que se nota una levemente menor precisi√≥n de dicha aproximaci√≥n para la curva 2 a comparaci√≥n de las dem√°s.

# ***3. Conclusiones generales***

A lo largo del trabajo se desarrollan y se alcanzan los objetivos propuestos al inicio del mismo, corroborando que los resultados te√≥ricos se ven reflejados en planteo realizado y en la aplicaci√≥n de m√©todos para estos problemas en particular.

# ***4. Referencias***

- Burden, R.L., Faires, J.D., An√°lisis Num√©rico. Grupo Editorial Iberoamericano, 1985.

- Apuntes del curso An√°lisis num√©rico 1 - curso Sassano - Facultad de Ingenier√≠a - Universidad de Buenos Aires - 2022. 

- Material audiovisual del curso An√°lisis num√©rico 1 - curso Sassano - Facultad de Ingenier√≠a - Universidad de Buenos Aires - 2022. 

- Manual de Latex,  https://manualdelatex.com/ .
"""